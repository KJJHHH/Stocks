{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Import and Set"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import sys \n","sys.path.append('../')\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import pickle\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from tqdm import tqdm\n","from utils import *\n","from models.Transformers import *\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","stock_symbol = '2454.TW'\n","end_date = '2024-12-31'\n","\n","\"\"\"\n","Trials:\n","    [decoder = {True, False}, num_class = {1, 2}]\n","Progress:\n","    [decoder = True, num_class = 1]\n","Pendng:\n","Finished:\n","    [decoder = False, num_class = 1] [decoder = True, num_class = 1]\n","\"\"\"\n","num_class = 1\n","init = True\n","fp16_training = True\n","num_epochs = 500\n","config = {\n","    'lr': 0.001,\n","}"]},{"cell_type":"markdown","metadata":{"id":"2dlPDr1feNdw"},"source":["# Data"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([64, 6, 10])\n"]}],"source":["if num_class == 1:\n","    with open('../DataLoader/dataloader_1.pk', 'rb') as f:\n","        data = pickle.load(f)\n","    trainloader = data['trainloader']\n","    validloader = data['validloader']\n","    # dataloader_test = data['testloader']\n","else:\n","    with open('../DataLoader/dataloader.pk', 'rb') as f:\n","        data = pickle.load(f)\n","    trainloader = data['trainloader']\n","    validloader = data['validloader']\n","    # dataloader_test = data['testloader']\n","with open('../DataLoader/src.pk', 'rb') as f:\n","    src = pickle.load(f)\n","    src = src.to(device)\n","\n","for x, y in trainloader:\n","    print(x.shape)\n","    break\n","batch_size = x.size(0)"]},{"cell_type":"markdown","metadata":{"id":"24AwH-nhes4f"},"source":["# Init"]},{"cell_type":"markdown","metadata":{},"source":["- Model, Criteria, Optimizer, Fp16, Previous Tarin Inofrmation"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accelerating\n","Init model\n","Last train epoch: 0  Last train lr: 0.001   Min val loss: 10000.0\n","Accelerate Prepare\n","Parameter 'embedding.weight' is on device: cuda:0\n"]}],"source":["\"\"\"\n","Choose if fp16 and define model\n","pip install accelerate==0.2.0\n","\"\"\"\n","# Model\n","if fp16_training:\n","    print('Accelerating')\n","    from accelerate import Accelerator\n","    accelerator = Accelerator()\n","    device = accelerator.device\n","    model = TransformerEncoderDecoder(num_class=num_class)\n","else:\n","    model = TransformerEncoderDecoder(num_class=num_class).to(device)\n","        \n","Model = model.model_type # Model name\n","\n","\"\"\"\n","Init for models, learning rate, ...\n","\"\"\"\n","# Check path\n","if os.path.exists(f'Temp//{Model}_{stock_symbol}_LastTrainInfo.pk'):\n","    # Check Init\n","    if init:\n","        print(\"Init model\")\n","        lr = config['lr']\n","        last_epoch = 0\n","        min_val_loss = 10000\n","        loss_train = []\n","        loss_valid = []\n","    else:\n","        print('Load from last train epoch')\n","        with open(f'Temp//{Model}_class{num_class}_{stock_symbol}_LastTrainInfo.pk', 'rb') as f:\n","            last_train_info = pickle.load(f)\n","        lr = last_train_info['lr']\n","        last_epoch = last_train_info['epoch']\n","        min_val_loss = last_train_info['min val loss']\n","        model.load_state_dict(torch.load(f'Temp//{Model}_class{num_class}_{stock_symbol}_checkpoint_LastTrainModel.pt'))\n","        with open(f'Temp//{Model}_class{num_class}_{stock_symbol}_TrainValHistLoss.pk', 'rb') as f:\n","            loss_train_val = pickle.load(f)\n","        loss_train = loss_train_val['train']\n","        loss_valid = loss_train_val['valid']\n","else:\n","    print(\"Init model\")\n","    lr = config['lr']\n","    last_epoch = 0\n","    min_val_loss = 10000.0\n","    loss_train = []\n","    loss_valid = []\n","print(f'Last train epoch: {last_epoch}  '\n","        f'Last train lr: {lr}   '\n","        f'Min val loss: {min_val_loss}')\n","\n","# Criterion and Optimizer\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.00001)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)        \n","\n","# Prepare\n","if fp16_training:\n","    print('Accelerate Prepare')    \n","    model, optimizer, trainloader, validloader, scheduler = \\\n","        accelerator.prepare(model, optimizer, trainloader, validloader, scheduler)\n","        \n","# Check device\n","for name, param in model.named_parameters():\n","    print(f\"Parameter '{name}' is on device: {param.device}\")\n","    break"]},{"cell_type":"markdown","metadata":{},"source":["# Train"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["(torch.Size([2000, 6, 1]),\n"," torch.Size([64, 6, 10]),\n"," 'TransEnDecoder-Window10EL128DL16Hid128')"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["for x, y in trainloader:\n","    break\n","src.shape, x.shape, Model"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 33/33 [00:47<00:00,  1.42s/it]\n","100%|██████████| 8/8 [00:00<00:00, 17.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["New best model found in epoch 0 with val loss: 3.8287645876407623\n","Epoch [0/500] Training Loss: 4.0647420847 Valid Loss: 3.8287645876\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 33/33 [00:46<00:00,  1.41s/it]\n","100%|██████████| 8/8 [00:00<00:00, 17.28it/s]\n"]},{"name":"stdout","output_type":"stream","text":["New best model found in epoch 1 with val loss: 3.7568734884262085\n","Epoch [1/500] Training Loss: 3.5605405388 Valid Loss: 3.7568734884\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 33/33 [00:46<00:00,  1.41s/it]\n","100%|██████████| 8/8 [00:00<00:00, 17.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["New best model found in epoch 2 with val loss: 3.6662782728672028\n","Epoch [2/500] Training Loss: 3.5448777314 Valid Loss: 3.6662782729\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 33/33 [00:46<00:00,  1.41s/it]\n","100%|██████████| 8/8 [00:00<00:00, 16.82it/s]\n"]},{"name":"stdout","output_type":"stream","text":["New best model found in epoch 3 with val loss: 3.6624887585639954\n","Epoch [3/500] Training Loss: 3.4435426683 Valid Loss: 3.6624887586\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 33/33 [00:46<00:00,  1.42s/it]\n","100%|██████████| 8/8 [00:00<00:00, 17.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["New best model found in epoch 4 with val loss: 3.64630788564682\n","Epoch [4/500] Training Loss: 3.3618068478 Valid Loss: 3.6463078856\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 33/33 [00:46<00:00,  1.42s/it]\n","100%|██████████| 8/8 [00:00<00:00, 16.86it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/500] Training Loss: 3.3130371932 Valid Loss: 3.6547852755\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 33/33 [00:48<00:00,  1.46s/it]\n","100%|██████████| 8/8 [00:00<00:00, 17.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [6/500] Training Loss: 3.2616745234 Valid Loss: 3.6464990377\n"]},{"name":"stderr","output_type":"stream","text":[" 79%|███████▉  | 26/33 [00:36<00:09,  1.42s/it]"]}],"source":["\"\"\"\n","--- Original ---------\n","batch_x: (batch_size, d_model, seqlen) \n","src: (total_length, d_model, seq_len)\n","--- Input of model ---\n","batch_x: (batch_size, seq_len, d_model) -> use src.permute()\n","src: (total_length, seq_len, d_model)   -> use batch.permute()\n","\"\"\"\n","# ==> src = src.permute(0, 2, 1)\n","src = src.squeeze(2).unsqueeze(0)\n","for epoch in range(last_epoch, num_epochs):\n","    # Training\n","    model.train()\n","    loss_train_e = 0\n","    for batch_x, batch_y in tqdm(trainloader): \n","        if not fp16_training:\n","            batch_x = batch_x.to(device)\n","            batch_y = batch_y.to(device)    \n","               \n","        batch_x = batch_x.permute(0, 2, 1)\n","        optimizer.zero_grad()\n","        \n","        if batch_x.size(0) != batch_size:\n","            continue\n","        memory, outputs = model(src=src, tgt=batch_x, train=True)\n","    \n","        # Loss\n","        loss = criterion(outputs, batch_y)\n","        if fp16_training:\n","            accelerator.backward(loss)\n","        else:\n","            loss.backward()\n","        optimizer.step()\n","        loss_train_e += loss.item()\n","    \n","    # Train loss\n","    loss_train_e /= len(trainloader)\n","    loss_train.append(loss_train_e)\n","    \n","    # Scheduler \n","    if epoch > 10:\n","        scheduler.step()\n","    \n","    # Validating\n","    loss_valid_e = 0\n","    with torch.no_grad():\n","        model.eval()\n","        for batch_x_val, batch_y_val in tqdm(validloader):\n","            # batch_x_val = mask(batch_x_val)\n","            if not fp16_training:\n","                batch_x_val = batch_x_val.to(device)\n","                batch_y_val = batch_y_val.to(device)\n","            batch_x_val = batch_x_val.permute(0, 2, 1)\n","            \n","            if batch_x_val.size(0) != batch_size:\n","                    continue\n","            memory, outputs_val = model(src, batch_x_val, False, memory)\n","                \n","            loss = criterion(outputs_val, batch_y_val)\n","            loss_valid_e += loss.item()\n","        loss_valid_e /= len(validloader)\n","        loss_valid.append(loss_valid_e)\n","            \n","        torch.save(model.state_dict(), f'Temp/{Model}_class{num_class}_{stock_symbol}_checkpoint_LastTrainModel.pt')\n","        if loss_valid_e < min_val_loss:\n","            min_val_loss = loss_valid_e\n","            print(f'New best model found in epoch {epoch} with val loss: {min_val_loss}')\n","            torch.save(model.state_dict(), f'Model_Result/{Model}_class{num_class}_{stock_symbol}_best_model.pt')            \n","        if epoch % 50 == 0:\n","            pass\n","            # torch.save(model, f'ConformerResult/Conformerr_{stock_symbol}_checkpoint_{epoch}.pt')\n","    \n","    # Store result    \n","    with open(f'Temp/{Model}_class{num_class}_{stock_symbol}_TrainValHistLoss.pk', 'wb') as f:\n","        pickle.dump({'train': loss_train, 'valid': loss_valid}, f)\n","    with open(f'Temp/{Model}_class{num_class}_{stock_symbol}_LastTrainInfo.pk', 'wb') as f:\n","        pickle.dump({'min val loss': min_val_loss, 'epoch': epoch, 'lr': optimizer.param_groups[0]['lr']}, f)\n","        \n","    # Print statistics\n","    print(f'Epoch [{epoch}/{num_epochs}]',\n","        f'Training Loss: {loss_train_e:.10f}',\n","        f'Valid Loss: {loss_valid_e:.10f}')"]}],"metadata":{"colab":{"collapsed_sections":["2dlPDr1feNdw","N2GtucuTfVrD","24AwH-nhes4f"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
