{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Import and Set"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import sys \n","sys.path.append('../')\n","import os\n","import pickle\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from tqdm import tqdm\n","from utils import *\n","from datas import *\n","from set_train import *\n","from models.Transformers import *\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","stock_symbol, end_date, num_class, batch_size, init, fp16_training, num_epochs, lr = set_train()\n","\n","# Data\n","trainloader, validloader, testloader, test_date, df, src = data()\n","for x, y in trainloader:\n","    break\n","print(src.device, x.device, src.shape, x.shape, y.shape)"]},{"cell_type":"markdown","metadata":{"id":"24AwH-nhes4f"},"source":["## Init: Model, Criteria, Optimizer, Fp16, Previous Tarin Inofrmation"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accelerating\n","Init model\n","Last train epoch: 0  Last train lr: 0.01   Min val loss: 10000.0\n","Accelerate Prepare\n","Parameter 'embedding.weight' is on device: cuda:0\n"]}],"source":["\"\"\"\n","Choose if fp16 and define model\n","pip install accelerate==0.2.0\n","\"\"\"\n","# Model\n","if fp16_training:\n","    from accelerate import Accelerator\n","    print('Accelerating')\n","    accelerator = Accelerator()\n","    device = accelerator.device\n","    model = TransformerEncoderDecoder(num_class=num_class)\n","else:\n","    model = TransformerEncoderDecoder(num_class=num_class).to(device)\n","        \n","Model = model.model_type # Model name\n","\n","\"\"\"\n","Init for models, learning rate, ...\n","\"\"\"\n","# Check path\n","if os.path.exists(f'Temp//{Model}_{stock_symbol}_LastTrainInfo.pk'):\n","    if init:\n","        print(\"Init model\")\n","        lr = lr\n","        last_epoch = 0\n","        min_val_loss = 10000\n","        loss_train = []\n","        loss_valid = []\n","    else:\n","        print('Load from last train epoch')\n","        model.load_state_dict(torch.load(f'Temp//{Model}_class{num_class}_{stock_symbol}_checkpoint_LastTrainModel.pt'))\n","        with open(f'Temp//{Model}_class{num_class}_{stock_symbol}_LastTrainInfo.pk', 'rb') as f:\n","            last_train_info = pickle.load(f)\n","        with open(f'Temp//{Model}_class{num_class}_{stock_symbol}_TrainValHistLoss.pk', 'rb') as f:\n","            loss_train_val = pickle.load(f)            \n","        lr = last_train_info['lr']\n","        last_epoch = last_train_info['epoch']\n","        min_val_loss = last_train_info['min val loss']\n","        loss_train = loss_train_val['train']\n","        loss_valid = loss_train_val['valid']\n","else:\n","        print(\"Init model\")\n","        lr = lr\n","        last_epoch = 0\n","        min_val_loss = 10000.0\n","        loss_train = []\n","        loss_valid = []\n","        \n","print(\n","    f'Last train epoch: {last_epoch}  '\n","    f'Last train lr: {lr}   '\n","    f'Min val loss: {min_val_loss}'\n","    )\n","\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.00001)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)        \n","\n","if fp16_training:\n","    print('Accelerate Prepare')    \n","    model, optimizer, trainloader, validloader, scheduler = \\\n","    accelerator.prepare(model, optimizer, trainloader, validloader, scheduler)\n","        \n","for name, param in model.named_parameters():\n","    print(f\"Parameter '{name}' is on device: {param.device}\")\n","    break"]},{"cell_type":"markdown","metadata":{},"source":["## Train"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["'TransEnDecoder-Window10EL512DL16Hid512'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["Model"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/33 [00:00<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 33/33 [02:06<00:00,  3.83s/it]\n","100%|██████████| 8/8 [00:00<00:00, 16.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["New best model found in epoch 0 with val loss: 5.258228182792664\n","Epoch [0/500] Training Loss: 4.4901149490 Valid Loss: 5.2582281828\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 33/33 [02:05<00:00,  3.80s/it]\n","100%|██████████| 8/8 [00:00<00:00, 17.29it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/500] Training Loss: 4.4503055955 Valid Loss: 5.2636268139\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 33/33 [02:23<00:00,  4.36s/it]\n","100%|██████████| 8/8 [00:00<00:00, 17.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/500] Training Loss: 4.4518440492 Valid Loss: 5.2746680677\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 33/33 [02:22<00:00,  4.31s/it]\n","100%|██████████| 8/8 [00:00<00:00, 17.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/500] Training Loss: 4.4551319462 Valid Loss: 5.3058543801\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 33/33 [02:06<00:00,  3.84s/it]\n","100%|██████████| 8/8 [00:00<00:00, 17.07it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/500] Training Loss: 4.4012405583 Valid Loss: 5.2598561645\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 33/33 [02:06<00:00,  3.83s/it]\n","100%|██████████| 8/8 [00:00<00:00, 17.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/500] Training Loss: 6.0752376065 Valid Loss: 5.3373350203\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 33/33 [02:05<00:00,  3.80s/it]\n","100%|██████████| 8/8 [00:00<00:00, 17.28it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [6/500] Training Loss: 4.4737970179 Valid Loss: 5.2911224663\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 33/33 [02:05<00:00,  3.81s/it]\n","100%|██████████| 8/8 [00:00<00:00, 17.27it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [7/500] Training Loss: 4.3853046099 Valid Loss: 5.2611436248\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 33/33 [02:05<00:00,  3.79s/it]\n","100%|██████████| 8/8 [00:00<00:00, 17.34it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [8/500] Training Loss: 4.4410319726 Valid Loss: 5.2765738070\n"]},{"name":"stderr","output_type":"stream","text":[" 91%|█████████ | 30/33 [02:11<00:11,  3.91s/it]"]}],"source":["\"\"\"\n","--- Original ---------\n","batch_x: (batch_size, d_model, seqlen) \n","src: (total_length, d_model, seq_len)\n","--- Input of model ---\n","batch_x: (batch_size, seq_len, d_model) -> use src.permute()\n","src: (total_length, seq_len, d_model)   -> use batch.permute()\n","\"\"\"\n","src = src.squeeze(2).unsqueeze(0).to(device)\n","for epoch in range(last_epoch, num_epochs):\n","    # Training\n","    model.train()\n","    loss_train_e = 0\n","    for batch_x, batch_y in tqdm(trainloader): \n","        # fp16\n","        if not fp16_training:\n","            batch_x = batch_x.to(device)\n","            batch_y = batch_y.to(device)            \n","        # Permute\n","        batch_x = batch_x.permute(0, 2, 1)        \n","        # Zero grad\n","        optimizer.zero_grad()        \n","        # Drop last batch\n","        if batch_x.size(0) != batch_size:\n","            continue        \n","        # Model\n","        memory, outputs = model(src=src, tgt=batch_x, train=True)    \n","        # Loss\n","        loss = criterion(outputs, batch_y)\n","        if fp16_training:\n","            accelerator.backward(loss)\n","        else:\n","            loss.backward()\n","        optimizer.step()\n","        loss_train_e += loss.item()\n","    \n","    # Train loss\n","    loss_train_e /= len(trainloader)\n","    loss_train.append(loss_train_e)\n","    \n","    # Scheduler \n","    if epoch > 10:\n","        scheduler.step()\n","    \n","    # Validating\n","    loss_valid_e = 0\n","    with torch.no_grad():\n","        model.eval()\n","        for batch_x_val, batch_y_val in tqdm(validloader):\n","            # batch_x_val = mask(batch_x_val)\n","            if not fp16_training:\n","                batch_x_val = batch_x_val.to(device)\n","                batch_y_val = batch_y_val.to(device)\n","            batch_x_val = batch_x_val.permute(0, 2, 1)\n","            \n","            if batch_x_val.size(0) != batch_size:\n","                    continue\n","            memory, outputs_val = model(src, batch_x_val, False, memory)\n","                \n","            loss = criterion(outputs_val, batch_y_val)\n","            loss_valid_e += loss.item()\n","        loss_valid_e /= len(validloader)\n","        loss_valid.append(loss_valid_e)\n","            \n","        torch.save(model.state_dict(), f'Temp/{Model}_class{num_class}_{stock_symbol}_checkpoint_LastTrainModel.pt')\n","        if loss_valid_e < min_val_loss:\n","            min_val_loss = loss_valid_e\n","            print(f'New best model found in epoch {epoch} with val loss: {min_val_loss}')\n","            torch.save(model.state_dict(), f'Model_Result/{Model}_class{num_class}_{stock_symbol}_best_model.pt')            \n","        if epoch % 50 == 0:\n","            pass\n","            # torch.save(model, f'ConformerResult/Conformerr_{stock_symbol}_checkpoint_{epoch}.pt')\n","    \n","    # Store result    \n","    with open(f'Temp/{Model}_class{num_class}_{stock_symbol}_TrainValHistLoss.pk', 'wb') as f:\n","        pickle.dump({'train': loss_train, 'valid': loss_valid}, f)\n","    with open(f'Temp/{Model}_class{num_class}_{stock_symbol}_LastTrainInfo.pk', 'wb') as f:\n","        pickle.dump({'min val loss': min_val_loss, 'epoch': epoch, 'lr': optimizer.param_groups[0]['lr']}, f)\n","        \n","    # Print statistics\n","    print(f'Epoch [{epoch}/{num_epochs}]',\n","        f'Training Loss: {loss_train_e:.10f}',\n","        f'Valid Loss: {loss_valid_e:.10f}')"]}],"metadata":{"colab":{"collapsed_sections":["2dlPDr1feNdw","N2GtucuTfVrD","24AwH-nhes4f"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
