{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Import and Set"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 2956/2956 [00:03<00:00, 960.30it/s] \n","100%|██████████| 2965/2965 [00:03<00:00, 813.81it/s] "]},{"name":"stdout","output_type":"stream","text":["x_train_len: 2128\n","cpu cpu torch.Size([2000, 6, 1]) torch.Size([128, 6, 10]) torch.Size([128, 2])\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["import sys \n","sys.path.append('../')\n","import os\n","import pickle\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from tqdm import tqdm\n","from utils import *\n","from datas import *\n","from set_train import *\n","from models.Transformers import *\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","stock_symbol, end_date, num_class, batch_size, init, fp16_training, num_epochs, lr = set_train()\n","\n","# Data\n","trainloader, validloader, testloader, test_date, df, src = data(num_class=num_class, batch_size=batch_size)\n","for x, y in trainloader:\n","    break\n","print(src.device, x.device, src.shape, x.shape, y.shape)"]},{"cell_type":"markdown","metadata":{"id":"24AwH-nhes4f"},"source":["## Init: Model, Criteria, Optimizer, Fp16, Previous Tarin Inofrmation"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accelerating\n","Init model\n","Last train epoch: 0  Last train lr: 0.01   Min val loss: 10000.0\n","Accelerate Prepare\n","Parameter 'embedding.weight' is on device: cuda:0\n"]}],"source":["\"\"\"\n","Choose if fp16 and define model\n","pip install accelerate==0.2.0\n","\"\"\"\n","# Model\n","if fp16_training:\n","    from accelerate import Accelerator\n","    print('Accelerating')\n","    accelerator = Accelerator()\n","    device = accelerator.device\n","    model = TransformerEncoderDecoder(num_class=num_class)\n","else:\n","    model = TransformerEncoderDecoder(num_class=num_class).to(device)\n","        \n","Model = model.model_type # Model name\n","\n","\"\"\"\n","Init for models, learning rate, ...\n","\"\"\"\n","# Check path\n","if os.path.exists(f'Temp//{Model}_{stock_symbol}_LastTrainInfo.pk'):\n","    if init:\n","        print(\"Init model\")\n","        lr = lr\n","        last_epoch = 0\n","        min_val_loss = 10000\n","        loss_train = []\n","        loss_valid = []\n","    else:\n","        print('Load from last train epoch')\n","        model.load_state_dict(torch.load(f'Temp//{Model}_class{num_class}_{stock_symbol}_checkpoint_LastTrainModel.pt'))\n","        with open(f'Temp//{Model}_class{num_class}_{stock_symbol}_LastTrainInfo.pk', 'rb') as f:\n","            last_train_info = pickle.load(f)\n","        with open(f'Temp//{Model}_class{num_class}_{stock_symbol}_TrainValHistLoss.pk', 'rb') as f:\n","            loss_train_val = pickle.load(f)            \n","        lr = last_train_info['lr']\n","        last_epoch = last_train_info['epoch']\n","        min_val_loss = last_train_info['min val loss']\n","        loss_train = loss_train_val['train']\n","        loss_valid = loss_train_val['valid']\n","else:\n","        print(\"Init model\")\n","        lr = lr\n","        last_epoch = 0\n","        min_val_loss = 10000.0\n","        loss_train = []\n","        loss_valid = []\n","        \n","print(\n","    f'Last train epoch: {last_epoch}  '\n","    f'Last train lr: {lr}   '\n","    f'Min val loss: {min_val_loss}'\n","    )\n","\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.00001)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)        \n","\n","if fp16_training:\n","    print('Accelerate Prepare')    \n","    model, optimizer, trainloader, validloader, scheduler = \\\n","    accelerator.prepare(model, optimizer, trainloader, validloader, scheduler)\n","        \n","for name, param in model.named_parameters():\n","    print(f\"Parameter '{name}' is on device: {param.device}\")\n","    break"]},{"cell_type":"markdown","metadata":{},"source":["## Train"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["'TransEnDecoder-Window10EL512DL16Hid512'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["Model"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 16/16 [01:31<00:00,  5.72s/it]\n","100%|██████████| 4/4 [00:00<00:00,  4.63it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [42/50] Training Loss: 4.19455 Valid Loss: 5.21695\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 16/16 [01:34<00:00,  5.89s/it]\n","100%|██████████| 4/4 [00:00<00:00,  4.63it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [43/50] Training Loss: 4.26757 Valid Loss: 5.21657\n"]},{"name":"stderr","output_type":"stream","text":[" 25%|██▌       | 4/16 [00:22<01:08,  5.72s/it]"]}],"source":["\"\"\"\n","--- Original ---------\n","batch_x: (batch_size, d_model, seqlen) \n","src: (total_length, d_model, seq_len)\n","--- Input of model ---\n","batch_x: (batch_size, seq_len, d_model) -> use src.permute()\n","src: (total_length, seq_len, d_model)   -> use batch.permute()\n","\"\"\"\n","src = src.squeeze(2).unsqueeze(0).to(device)\n","for epoch in range(last_epoch, num_epochs):\n","    # Training\n","    model.train()\n","    loss_train_e = 0\n","    for batch_x, batch_y in tqdm(trainloader): \n","        # fp16\n","        if not fp16_training:\n","            batch_x = batch_x.to(device)\n","            batch_y = batch_y.to(device)            \n","        # Permute\n","        batch_x = batch_x.permute(0, 2, 1)        \n","        # Zero grad\n","        optimizer.zero_grad()        \n","        # Drop last batch\n","        if batch_x.size(0) != batch_size:\n","            continue        \n","        # Model\n","        memory, outputs = model(src=src, tgt=batch_x, train=True)    \n","        # Loss\n","        loss = criterion(outputs, batch_y)\n","        if fp16_training:\n","            accelerator.backward(loss)\n","        else:\n","            loss.backward()\n","        optimizer.step()\n","        loss_train_e += loss.item()\n","    \n","    # Train loss\n","    loss_train_e /= len(trainloader)\n","    loss_train.append(loss_train_e)\n","    \n","    # Scheduler \n","    if epoch > 10:\n","        scheduler.step()\n","    \n","    # Validating\n","    loss_valid_e = 0\n","    with torch.no_grad():\n","        model.eval()\n","        for batch_x_val, batch_y_val in tqdm(validloader):\n","            # batch_x_val = mask(batch_x_val)\n","            if not fp16_training:\n","                batch_x_val = batch_x_val.to(device)\n","                batch_y_val = batch_y_val.to(device)\n","            batch_x_val = batch_x_val.permute(0, 2, 1)\n","            \n","            if batch_x_val.size(0) != batch_size:\n","                    continue\n","            memory, outputs_val = model(src, batch_x_val, False, memory)\n","                \n","            loss = criterion(outputs_val, batch_y_val)\n","            loss_valid_e += loss.item()\n","        loss_valid_e /= len(validloader)\n","        loss_valid.append(loss_valid_e)\n","            \n","        torch.save(model.state_dict(), f'Temp/{Model}_class{num_class}_{stock_symbol}_checkpoint_LastTrainModel.pt')\n","        if loss_valid_e < min_val_loss:\n","            min_val_loss = loss_valid_e\n","            print(f'New best model found in epoch {epoch} with val loss: {min_val_loss}')\n","            torch.save(model.state_dict(), f'Model_Result/{Model}_class{num_class}_{stock_symbol}_best_model.pt')            \n","        if epoch % 50 == 0:\n","            pass\n","            # torch.save(model, f'ConformerResult/Conformerr_{stock_symbol}_checkpoint_{epoch}.pt')\n","     \n","    with open(f'Temp/{Model}_class{num_class}_{stock_symbol}_TrainValHistLoss.pk', 'wb') as f:\n","        pickle.dump({'train': loss_train, 'valid': loss_valid}, f)\n","    with open(f'Temp/{Model}_class{num_class}_{stock_symbol}_LastTrainInfo.pk', 'wb') as f:\n","        pickle.dump({'min val loss': min_val_loss, 'epoch': epoch, 'lr': optimizer.param_groups[0]['lr']}, f)        \n","    print(\n","        f'Epoch [{epoch}/{num_epochs}]',\n","        f'Training Loss: {loss_train_e:.5f}',\n","        f'Valid Loss: {loss_valid_e:.5f}'\n","        )"]}],"metadata":{"colab":{"collapsed_sections":["2dlPDr1feNdw","N2GtucuTfVrD","24AwH-nhes4f"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
