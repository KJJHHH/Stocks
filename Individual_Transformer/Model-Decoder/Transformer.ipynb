{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Import and Set"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import sys \n","sys.path.append('../')\n","import os\n","import pickle\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from tqdm import tqdm\n","from utils import *\n","from datas import *\n","from set_train import *\n","from models.Transformers import *\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","stock_symbol, end_date, num_class, batch_size, init, fp16_training, num_epochs, lr = set_train()\n","\n","# Data\n","trainloader, validloader, testloader, test_date, df, src = data()\n","for x, y in trainloader:\n","    break\n","print(src.device, x.device, src.shape, x.shape, y.shape)"]},{"cell_type":"markdown","metadata":{"id":"24AwH-nhes4f"},"source":["## Init: Model, Criteria, Optimizer, Fp16, Previous Tarin Inofrmation"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accelerating\n","Init model\n","Last train epoch: 0  Last train lr: 0.001   Min val loss: 10000.0\n","Accelerate Prepare\n","Parameter 'embedding.weight' is on device: cuda:0\n"]}],"source":["\"\"\"\n","Choose if fp16 and define model\n","pip install accelerate==0.2.0\n","\"\"\"\n","# Model\n","if fp16_training:\n","    print('Accelerating')\n","    from accelerate import Accelerator\n","    accelerator = Accelerator()\n","    device = accelerator.device\n","    model = TransformerDecoderOnly(num_class=num_class)\n","else:\n","    model = TransformerDecoderOnly(num_class=num_class).to(device)\n","        \n","Model = model.model_type # Model name\n","\n","\"\"\"\n","Init for models, learning rate, ...\n","\"\"\"\n","# Check path\n","if os.path.exists(f'Temp//{Model}_{stock_symbol}_LastTrainInfo.pk'):\n","    # Check Init\n","    if init:\n","        print(\"Init model\")\n","        lr = lr\n","        last_epoch = 0\n","        min_val_loss = 10000\n","        loss_train = []\n","        loss_valid = []\n","    else:\n","        print('Load from last train epoch')\n","        with open(f'Temp//{Model}_class{num_class}_{stock_symbol}_LastTrainInfo.pk', 'rb') as f:\n","            last_train_info = pickle.load(f)\n","        lr = last_train_info['lr']\n","        last_epoch = last_train_info['epoch']\n","        min_val_loss = last_train_info['min val loss']\n","        model.load_state_dict(torch.load(f'Temp//{Model}_class{num_class}_{stock_symbol}_checkpoint_LastTrainModel.pt'))\n","        with open(f'Temp//{Model}_class{num_class}_{stock_symbol}_TrainValHistLoss.pk', 'rb') as f:\n","            loss_train_val = pickle.load(f)\n","        loss_train = loss_train_val['train']\n","        loss_valid = loss_train_val['valid']\n","else:\n","    print(\"Init model\")\n","    lr = lr\n","    last_epoch = 0\n","    min_val_loss = 10000.0\n","    loss_train = []\n","    loss_valid = []\n","print(f'Last train epoch: {last_epoch}  '\n","        f'Last train lr: {lr}   '\n","        f'Min val loss: {min_val_loss}')\n","\n","# Criterion and Optimizer\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.00001)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=len(trainloader)*1, gamma=0.9)        \n","\n","# Prepare\n","if fp16_training:\n","    print('Accelerate Prepare')    \n","    model, optimizer, trainloader, validloader, scheduler = \\\n","        accelerator.prepare(model, optimizer, trainloader, validloader, scheduler)\n","        \n","# Check device\n","for name, param in model.named_parameters():\n","    print(f\"Parameter '{name}' is on device: {param.device}\")\n","    break"]},{"cell_type":"markdown","metadata":{},"source":["## Train"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:27<00:00,  2.38it/s]\n","100%|██████████| 17/17 [00:02<00:00,  7.27it/s]\n"]},{"name":"stdout","output_type":"stream","text":["New best model found in epoch 0 with val loss: 4.802058163811179\n","Epoch [0/500] Training Loss: 6.7612539897 Valid Loss: 4.8020581638\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:27<00:00,  2.39it/s]\n","100%|██████████| 17/17 [00:02<00:00,  7.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["New best model found in epoch 1 with val loss: 3.9283670870696796\n","Epoch [1/500] Training Loss: 5.3817783374 Valid Loss: 3.9283670871\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:25<00:00,  2.58it/s]\n","100%|██████████| 17/17 [00:02<00:00,  6.79it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/500] Training Loss: 4.4216169532 Valid Loss: 3.9749437360\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:28<00:00,  2.28it/s]\n","100%|██████████| 17/17 [00:02<00:00,  7.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["New best model found in epoch 3 with val loss: 3.6457891814848957\n","Epoch [3/500] Training Loss: 3.9063395739 Valid Loss: 3.6457891815\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:28<00:00,  2.28it/s]\n","100%|██████████| 17/17 [00:02<00:00,  7.75it/s]\n"]},{"name":"stdout","output_type":"stream","text":["New best model found in epoch 4 with val loss: 3.44402439103407\n","Epoch [4/500] Training Loss: 3.3885348403 Valid Loss: 3.4440243910\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:29<00:00,  2.19it/s]\n","100%|██████████| 17/17 [00:02<00:00,  8.12it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/500] Training Loss: 3.1015004048 Valid Loss: 3.4481418063\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:26<00:00,  2.43it/s]\n","100%|██████████| 17/17 [00:02<00:00,  8.18it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [6/500] Training Loss: 2.8381008662 Valid Loss: 3.5358751802\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:26<00:00,  2.41it/s]\n","100%|██████████| 17/17 [00:02<00:00,  7.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["New best model found in epoch 7 with val loss: 3.438989288666669\n","Epoch [7/500] Training Loss: 2.7208757932 Valid Loss: 3.4389892887\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:29<00:00,  2.17it/s]\n","100%|██████████| 17/17 [00:02<00:00,  7.18it/s]\n"]},{"name":"stdout","output_type":"stream","text":["New best model found in epoch 8 with val loss: 3.4004140601438633\n","Epoch [8/500] Training Loss: 2.6073050343 Valid Loss: 3.4004140601\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:26<00:00,  2.46it/s]\n","100%|██████████| 17/17 [00:02<00:00,  7.24it/s]\n"]},{"name":"stdout","output_type":"stream","text":["New best model found in epoch 9 with val loss: 3.3696217046064487\n","Epoch [9/500] Training Loss: 2.5382995505 Valid Loss: 3.3696217046\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:27<00:00,  2.40it/s]\n","100%|██████████| 17/17 [00:02<00:00,  6.19it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [10/500] Training Loss: 2.3800497211 Valid Loss: 3.5346867968\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:33<00:00,  1.97it/s]\n","100%|██████████| 17/17 [00:02<00:00,  6.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [11/500] Training Loss: 2.3963333199 Valid Loss: 3.4133140760\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:30<00:00,  2.12it/s]\n","100%|██████████| 17/17 [00:03<00:00,  4.26it/s]\n"]},{"name":"stdout","output_type":"stream","text":["New best model found in epoch 12 with val loss: 3.3571436825920555\n","Epoch [12/500] Training Loss: 2.2193017905 Valid Loss: 3.3571436826\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:28<00:00,  2.31it/s]\n","100%|██████████| 17/17 [00:02<00:00,  6.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [13/500] Training Loss: 2.2081146020 Valid Loss: 3.3640461459\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:31<00:00,  2.09it/s]\n","100%|██████████| 17/17 [00:03<00:00,  5.34it/s]\n"]},{"name":"stdout","output_type":"stream","text":["New best model found in epoch 14 with val loss: 3.313370199764476\n","Epoch [14/500] Training Loss: 2.2039817095 Valid Loss: 3.3133701998\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:34<00:00,  1.86it/s]\n","100%|██████████| 17/17 [00:03<00:00,  5.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [15/500] Training Loss: 2.2043683162 Valid Loss: 3.3479923431\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:35<00:00,  1.83it/s]\n","100%|██████████| 17/17 [00:02<00:00,  6.86it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [16/500] Training Loss: 2.1747766476 Valid Loss: 3.3624612794\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:32<00:00,  2.01it/s]\n","100%|██████████| 17/17 [00:02<00:00,  7.67it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [17/500] Training Loss: 2.2151739515 Valid Loss: 3.4696638584\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:33<00:00,  1.96it/s]\n","100%|██████████| 17/17 [00:02<00:00,  5.71it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [18/500] Training Loss: 2.2020364908 Valid Loss: 3.4768973519\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:31<00:00,  2.08it/s]\n","100%|██████████| 17/17 [00:02<00:00,  5.84it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [19/500] Training Loss: 2.1996129118 Valid Loss: 3.4123303469\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:31<00:00,  2.07it/s]\n","100%|██████████| 17/17 [00:02<00:00,  5.78it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [20/500] Training Loss: 2.2081970948 Valid Loss: 3.4076033901\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:28<00:00,  2.26it/s]\n","100%|██████████| 17/17 [00:02<00:00,  7.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [21/500] Training Loss: 2.1244901318 Valid Loss: 3.4354408068\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:27<00:00,  2.33it/s]\n","100%|██████████| 17/17 [00:02<00:00,  7.72it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [22/500] Training Loss: 2.1624132528 Valid Loss: 3.4048803133\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:29<00:00,  2.17it/s]\n","100%|██████████| 17/17 [00:02<00:00,  7.12it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [23/500] Training Loss: 2.1153532257 Valid Loss: 3.4347504518\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:26<00:00,  2.50it/s]\n","100%|██████████| 17/17 [00:02<00:00,  7.85it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [24/500] Training Loss: 2.1499823602 Valid Loss: 3.3912314247\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:25<00:00,  2.51it/s]\n","100%|██████████| 17/17 [00:02<00:00,  7.62it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [25/500] Training Loss: 2.1130768927 Valid Loss: 3.4474867021\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:25<00:00,  2.57it/s]\n","100%|██████████| 17/17 [00:02<00:00,  7.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [26/500] Training Loss: 2.1585642673 Valid Loss: 3.5158348224\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:25<00:00,  2.53it/s]\n","100%|██████████| 17/17 [00:02<00:00,  6.71it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [27/500] Training Loss: 2.1174029905 Valid Loss: 3.4587985137\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:26<00:00,  2.45it/s]\n","100%|██████████| 17/17 [00:02<00:00,  7.92it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [28/500] Training Loss: 2.1027837309 Valid Loss: 3.4400942185\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:33<00:00,  1.92it/s]\n","100%|██████████| 17/17 [00:03<00:00,  5.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [29/500] Training Loss: 2.0972872995 Valid Loss: 3.4603089445\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|████████  | 52/65 [00:32<00:07,  1.77it/s]"]}],"source":["\"\"\"\n","--- Original ---------\n","batch_x: (batch_size, d_model, seqlen) \n","src: (total_length, d_model, seq_len)\n","--- Input of model ---\n","batch_x: (batch_size, seq_len, d_model) -> use src.permute()\n","src: (total_length, seq_len, d_model)   -> use batch.permute()\n","\"\"\"\n","src = src.squeeze(2).unsqueeze(0).to(device)\n","for epoch in range(last_epoch, num_epochs):\n","    # Training phase\n","    model.train()\n","    loss_train_e = 0\n","    for batch_x, batch_y in tqdm(trainloader): \n","        if not fp16_training:\n","            batch_x = batch_x.to(device)\n","            batch_y = batch_y.to(device)    \n","               \n","        batch_x = batch_x.permute(0, 2, 1)\n","        optimizer.zero_grad()\n","        \n","        outputs = model(batch_x)\n","        \n","    \n","        # Loss\n","        loss = criterion(outputs, batch_y)\n","        if fp16_training:\n","            accelerator.backward(loss)\n","        else:\n","            loss.backward()\n","        optimizer.step()\n","        if epoch > 50:\n","            scheduler.step()\n","        loss_train_e += loss.item()\n","        \n","    loss_train_e /= len(trainloader)\n","    loss_train.append(loss_train_e)\n","    \n","    loss_valid_e = 0\n","    with torch.no_grad():\n","        model.eval()\n","        for batch_x_val, batch_y_val in tqdm(validloader):\n","            # batch_x_val = mask(batch_x_val)\n","            if not fp16_training:\n","                batch_x_val = batch_x_val.to(device)\n","                batch_y_val = batch_y_val.to(device)\n","            batch_x_val = batch_x_val.permute(0, 2, 1)\n","            \n","            outputs_val = model(batch_x_val)\n","            loss = criterion(outputs_val, batch_y_val)\n","            loss_valid_e += loss.item()\n","        loss_valid_e /= len(validloader)\n","        loss_valid.append(loss_valid_e)\n","            \n","        torch.save(model.state_dict(), f'Temp/{Model}_class{num_class}_{stock_symbol}_checkpoint_LastTrainModel.pt')\n","        if loss_valid_e < min_val_loss:\n","            min_val_loss = loss_valid_e\n","            print(f'New best model found in epoch {epoch} with val loss: {min_val_loss}')\n","            torch.save(model.state_dict(), f'Model_Result/{Model}_class{num_class}_{stock_symbol}_best_model.pt')            \n","        if epoch % 50 == 0:\n","            pass\n","            # torch.save(model, f'ConformerResult/Conformerr_{stock_symbol}_checkpoint_{epoch}.pt')\n","            \n","    with open(f'Temp/{Model}_class{num_class}_{stock_symbol}_TrainValHistLoss.pk', 'wb') as f:\n","        pickle.dump({'train': loss_train, 'valid': loss_valid}, f)\n","    with open(f'Temp/{Model}_class{num_class}_{stock_symbol}_LastTrainInfo.pk', 'wb') as f:\n","        pickle.dump({'min val loss': min_val_loss, 'epoch': epoch, 'lr': optimizer.param_groups[0]['lr']}, f)\n","        \n","    # Print statistics\n","    print(f'Epoch [{epoch}/{num_epochs}]',\n","        f'Training Loss: {loss_train_e:.10f}',\n","        f'Valid Loss: {loss_valid_e:.10f}')"]}],"metadata":{"colab":{"collapsed_sections":["2dlPDr1feNdw","N2GtucuTfVrD","24AwH-nhes4f"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
