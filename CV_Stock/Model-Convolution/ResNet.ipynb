{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Import and Set"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import sys\n","sys.path.append('../')\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import MinMaxScaler\n","import yfinance as yf\n","import numpy as np\n","import os\n","import pickle\n","from torchaudio.models import Conformer\n","import math\n","from torch import nn, Tensor\n","from tqdm import tqdm\n","import torch\n","import torchvision\n","import torch.nn as nn\n","from utils import *\n","from models.Resnet import resnet50\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","num_class = 2\n","stock_symbol = '5871.TW'\n","end_date = '2024-12-31'\n","init = True\n","num_epochs = 500"]},{"cell_type":"markdown","metadata":{"id":"2dlPDr1feNdw"},"source":["# Data"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["if num_class == 1:\n","    with open('../DataLoader/dataloader_1.pk', 'rb') as f:\n","        data = pickle.load(f)\n","    dataloader_train = data['trainloader']\n","    dataloader_valid = data['validloader']\n","else:\n","    with open('../DataLoader/dataloader.pk', 'rb') as f:\n","        data = pickle.load(f)\n","    dataloader_train = data['trainloader']\n","    dataloader_valid = data['validloader']\n","    "]},{"cell_type":"markdown","metadata":{"id":"24AwH-nhes4f"},"source":["# Train"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["'2.13e+07'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# !pip install accelerate==0.2.0\n","fp16_training = False\n","\n","if fp16_training:\n","    print('Accelerating')\n","    from accelerate import Accelerator\n","    accelerator = Accelerator(fp16=True)\n","    device = accelerator.device\n","    model = resnet50(num_class).to(device)\n","else:\n","    model = resnet50(num_class).to(device)\n","\n","Model = model.model_type\n","total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\"{:.2e}\".format(total_params)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Init model\n","Last train epoch: 0  Last train lr: 0.0001   Min val loss: 10000.0\n"]}],"source":["# !pip install accelerate==0.2.0\n","fp16_training = False\n","\n","if fp16_training:\n","    print('Accelerating')\n","    from accelerate import Accelerator\n","    accelerator = Accelerator(fp16=True)\n","    device = accelerator.device\n","    model = resnet50(num_class).to(device)\n","else:\n","    model = resnet50(num_class).to(device)\n","\n","total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\"{:.2e}\".format(total_params)\n","\n","if os.path.exists(f'Temp//{Model}_class{num_class}_{stock_symbol}_LastTrainInfo.pk'):\n","    if init:\n","        print(\"Init model\")\n","        lr = 0.0001\n","        last_epoch = 0\n","        min_val_loss = 10000.0\n","        loss_train = []\n","        loss_valid = []\n","    else:\n","        print('Load from last train epoch')\n","        with open(f'Temp//{Model}_class{num_class}_{stock_symbol}_LastTrainInfo.pk', 'rb') as f:\n","            last_train_info = pickle.load(f)\n","        lr = last_train_info['lr']\n","        last_epoch = last_train_info['epoch']\n","        min_val_loss = last_train_info['min val loss']\n","        model.load_state_dict(torch.load(f'Temp//{Model}_class{num_class}_{stock_symbol}_checkpoint_LastTrainModel.pt'))\n","        with open(f'Temp//{Model}_class{num_class}_{stock_symbol}_TrainValHistLoss.pk', 'rb') as f:\n","            loss_train_val = pickle.load(f)\n","        loss_train = loss_train_val['train']\n","        loss_valid = loss_train_val['valid']\n","else:\n","    print(\"Init model\")\n","    lr = 0.0001\n","    last_epoch = 0\n","    min_val_loss = 10000.0\n","    loss_train = []\n","    loss_valid = []    \n","print(f'Last train epoch: {last_epoch}  '\n","        f'Last train lr: {lr}   '\n","        f'Min val loss: {min_val_loss}')\n","\n","import torch.optim as optim\n","import pickle\n","\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.00001)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=len(dataloader_train)*10, gamma=0.9)        \n","\n","if fp16_training:\n","    print('Accelerate Prepare')\n","    model, optimizer, dataloader_train, dataloader_valid, scheduler = \\\n","        accelerator.prepare(model, optimizer, dataloader_train, dataloader_valid, scheduler)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:27<00:00,  2.36it/s]\n","100%|██████████| 17/17 [00:02<00:00,  7.77it/s]\n"]},{"name":"stdout","output_type":"stream","text":["New best model found in epoch 0 with val loss: 4.487863561686347\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/65 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [0/500] Training Loss: 3.5456123270 Valid Loss: 4.4878635617\n"]},{"name":"stderr","output_type":"stream","text":[" 14%|█▍        | 9/65 [00:03<00:23,  2.38it/s]"]}],"source":["for epoch in range(last_epoch, num_epochs):\n","    # Training phase\n","    model.train()\n","    loss_train_e = 0\n","    for batch_x, batch_y in tqdm(dataloader_train):\n","        # batch_x = mask(batch_x)\n","        if not fp16_training:\n","            batch_x = batch_x.to(device)\n","            batch_y = batch_y.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(batch_x)\n","\n","        # Loss\n","        loss = criterion(outputs, batch_y)\n","        if fp16_training:\n","            accelerator.backward(loss)\n","        else:\n","            loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        loss_train_e += loss.item()\n","        \n","    loss_train_e /= len(dataloader_train)\n","    loss_train.append(loss_train_e)\n","    \n","    loss_valid_e = 0\n","    with torch.no_grad():\n","        model.eval()\n","        for batch_x_val, batch_y_val in tqdm(dataloader_valid):\n","            # batch_x_val = mask(batch_x_val)\n","            if not fp16_training:\n","                batch_x_val = batch_x_val.to(device)\n","                batch_y_val = batch_y_val.to(device)\n","            outputs_val = model(batch_x_val)\n","            loss = criterion(outputs_val, batch_y_val)\n","            loss_valid_e += loss.item()\n","        loss_valid_e /= len(dataloader_valid)\n","        loss_valid.append(loss_valid_e)\n","            \n","        torch.save(model.state_dict(), f'Temp/{Model}_class{num_class}_{stock_symbol}_checkpoint_LastTrainModel.pt')\n","        if loss_valid_e < min_val_loss:\n","            min_val_loss = loss_valid_e\n","            print(f'New best model found in epoch {epoch} with val loss: {min_val_loss}')\n","            torch.save(model.state_dict(), f'Result/{Model}_class{num_class}_{stock_symbol}_best_model.pt')            \n","        if epoch % 50 == 0:\n","            pass\n","            # torch.save(model, f'ConformerResult/Conformerr_{stock_symbol}_checkpoint_{epoch}.pt')\n","            \n","    with open(f'Temp/{Model}_class{num_class}_{stock_symbol}_TrainValHistLoss.pk', 'wb') as f:\n","        pickle.dump({'train': loss_train, 'valid': loss_valid}, f)\n","    with open(f'Temp/{Model}_class{num_class}_{stock_symbol}_LastTrainInfo.pk', 'wb') as f:\n","        pickle.dump({'min val loss': min_val_loss, 'epoch': epoch, 'lr': optimizer.param_groups[0]['lr']}, f)\n","        \n","    # Print statistics\n","    print(f'Epoch [{epoch}/{num_epochs}]',\n","        f'Training Loss: {loss_train_e:.10f}',\n","        f'Valid Loss: {loss_valid_e:.10f}')"]},{"cell_type":"markdown","metadata":{"id":"gdsTCRhq_a_O"},"source":["# Validate Model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1708508308097,"user":{"displayName":"Kuo Jacob","userId":"03725230422177139348"},"user_tz":-480},"id":"Xr_xzxUygrCM"},"outputs":[],"source":["def load_model():\n","    import torch\n","    model = torch.load(f'ConformerResult/Conformer_{stock_symbol}_best_model.pt')\n","    return model\n","model = load_model()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":46476,"status":"ok","timestamp":1708508354571,"user":{"displayName":"Kuo Jacob","userId":"03725230422177139348"},"user_tz":-480},"id":"-Vxhjr2bfVrJ"},"outputs":[],"source":["\n","import gc\n","def test():\n","    dataloader = dataloader_test\n","\n","    model.eval()\n","    s_pred = []\n","    s_true = []\n","    for x, y in tqdm(dataloader):\n","        y_pred = model(x)\n","        s_pred.append(y_pred.detach())\n","        s_true.append(y)\n","    y_pred_tensor = torch.concat(s_pred)\n","    y_test_tensor = torch.concat(s_true)\n","    accuracy = (torch.sign(y_pred_tensor) == torch.sign(y_test_tensor)).sum() / len(y_test_tensor)\n","    return y_pred_tensor, accuracy\n","\n","y_pred, acc = test()\n","print(acc)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18330,"status":"ok","timestamp":1708508372899,"user":{"displayName":"Kuo Jacob","userId":"03725230422177139348"},"user_tz":-480},"id":"wMKUVbcfj8zX"},"outputs":[],"source":["# Derive y_pred and y_train_pred of shape(N, 2) and numpy type\n","\n","y_pred_numpy = y_pred.cpu().numpy()\n","\n","# predict with train set\n","y_train_pred = model(torch.tensor(X[-100:], dtype = torch.float32))\n","y_train_numpy = y_train_pred.detach().cpu().numpy()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iKLtCWerEIac"},"outputs":[],"source":["import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","\n","# Scaling\n","prediction = pd.DataFrame(y_pred_numpy)\n","scaler = StandardScaler()\n","scaler.fit(y_train_numpy)\n","prediction = pd.DataFrame(scaler.transform(prediction))\n","\n","# Get the predicted price of O and C and Prediction merge with complete data\n","prediction.columns = ['pred_do_1', 'pred_dc_1']\n","prediction['Date'] = date\n","\n","true_and_pred = pd.merge(df.reset_index(), prediction, on = 'Date', how = 'left')\n","true_and_pred['pred_o'] = (true_and_pred['Open'] * (1 + true_and_pred['pred_do_1'])).shift(1)\n","true_and_pred['pred_c'] = (true_and_pred['Close'] * (1 + true_and_pred['pred_dc_1'])).shift(1)\n","true_and_pred['pred_oc'] = true_and_pred['pred_c'] - true_and_pred['pred_o']\n","true_and_pred['true_oc'] = true_and_pred['Close'] - true_and_pred['Open']\n","\n","# Backtest\n","asset_list = []\n","df_backtest = true_and_pred[['Open', 'Close', 'true_oc', 'pred_oc']].dropna()\n","asset = 1\n","for index, (o, c, true, pred) in df_backtest.iterrows():\n","    if pred > 0:\n","        returns = true/o\n","        asset *= (1 + returns)\n","    asset_list.append(asset)\n","\n","print(asset)\n","plt.plot(asset_list, label = 'resnet')\n","plt.plot(df_backtest.reset_index()['Close']/df_backtest['Close'].iloc[0], label = 'buy hold')\n","plt.legend()\n","plt.savefig('/ConformerResult/test_backtest.jpg')\n","# plt.show()"]}],"metadata":{"colab":{"collapsed_sections":["2dlPDr1feNdw","N2GtucuTfVrD","24AwH-nhes4f"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
