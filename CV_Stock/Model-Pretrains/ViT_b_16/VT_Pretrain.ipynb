{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Import and Set"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import sys\n","sys.path.append('../../')\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import MinMaxScaler\n","import yfinance as yf\n","import numpy as np\n","import os\n","import pickle\n","from torchaudio.models import Conformer\n","import math\n","from torch import nn, Tensor\n","from tqdm import tqdm\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.preprocessing import Normalizer, StandardScaler\n","from einops.layers.torch import Rearrange, Reduce\n","from utils import *\n","from model import VT_CNN\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","num_class = 2\n","stock_symbol = '5871.TW'\n","end_date = '2024-12-31'\n","\n","init = False\n","batch_size = 8\n","lr = 0.0001\n","num_epochs = 50"]},{"cell_type":"markdown","metadata":{"id":"2dlPDr1feNdw"},"source":["# Init and Data"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/jacob/anaconda3/envs/mlntu/lib/python3.10/site-packages/yfinance/utils.py:775: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n","  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n","/tmp/ipykernel_75809/3398650488.py:25: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df[['do', 'dh', 'dl', 'dc', 'dv']] = scaler.fit_transform(df[['do', 'dh', 'dl', 'dc', 'dv']])\n","100%|██████████| 2725/2725 [00:05<00:00, 526.53it/s]\n","100%|██████████| 2725/2725 [00:22<00:00, 120.34it/s]\n"]}],"source":["# 擷取股票價格資訊\n","stock_price_data = fetch_stock_price(stock_symbol=stock_symbol, start_date='2012-01-02',end_date=end_date)\n","\n","stock_price_data['do'] = stock_price_data['Open'].pct_change()\n","stock_price_data['dh'] = stock_price_data['High'].pct_change()\n","stock_price_data['dl'] = stock_price_data['Low'].pct_change()\n","stock_price_data['dc'] = stock_price_data['Close'].pct_change()\n","stock_price_data['dv'] = stock_price_data['Volume'].pct_change()\n","\n","stock_price_data['do_1'] = stock_price_data['do'].shift(-1)\n","stock_price_data['dc_1'] = stock_price_data['dc'].shift(-1)\n","stock_price_data['(o-c)_1'] = (stock_price_data['Open'].shift(-1) - stock_price_data['Close'])/stock_price_data['Close']\n","\n","stock_price_data = stock_price_data.dropna()\n","\n","# df = stock_price_data.iloc[:,7:]\n","df = stock_price_data\n","# Replace infinite values with NaN\n","df.replace([np.inf, -np.inf], np.nan, inplace=True)\n","\n","# Drop rows with NaN values\n","df = df.dropna()\n","scaler = StandardScaler()\n","scaler.fit(df[['do', 'dh', 'dl', 'dc', 'dv']][:2000])\n","df[['do', 'dh', 'dl', 'dc', 'dv']] = scaler.fit_transform(df[['do', 'dh', 'dl', 'dc', 'dv']])\n","\n","# Scaler\n","\n","def processing():\n","    \"\"\"\n","    If not use a function, torch.cuda.empty not work\n","    \"\"\"\n","    x, y, date = window_x_y(df, 224)\n","    X = process_x(x)\n","    X, x_test, y, y_test = train_test(X, y)\n","    x_train, x_valid, y_train, y_valid = train_valid(X, y)\n","\n","    trainloader, validloader, testloader = (\n","        loader(x_train.cpu(), torch.tensor(y_train).to(dtype=torch.float32), batch_size=batch_size), \n","        loader(x_valid.cpu(), torch.tensor(y_valid).to(dtype=torch.float32), batch_size=batch_size),\n","        loader(x_test.cpu(), torch.tensor(y_test).to(dtype=torch.float32), batch_size=batch_size)\n","        )    \n","    test_date = df.index[-len(y_test):]\n","    return trainloader, validloader, testloader, test_date\n","\n","trainloader, validloader, testloader, test_date = processing()\n","torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{},"source":["# Setting\n","- Model, Optimizer, ..."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accelerating\n","Load from last train epoch\n","Last train epoch: 3  Last train lr: 0.0001   Min val loss: 0.0005550204547152164\n","Accelerate Prepare\n"]}],"source":["# Accelerate\n","# !pip install accelerate==0.2.0\n","\"\"\"\n","Don't know why 16 not working\n","\"\"\"\n","fp16_training = True\n","if fp16_training:\n","    print('Accelerating')\n","    from accelerate import Accelerator\n","    accelerator = Accelerator()\n","    device = accelerator.device\n","    model = VT_CNN()\n","else:\n","    model = VT_CNN().to(device)\n","\n","# Load previous\n","if os.path.exists(f'Temp//Conformer_{stock_symbol}_LastTrainInfo.pk'):\n","    if init:\n","        print(\"Init model\")\n","        lr = lr\n","        last_epoch = 0\n","        min_val_loss = 10000.0\n","        loss_train = []\n","        loss_valid = []\n","    else:\n","        print('Load from last train epoch')\n","        with open(f'Temp//Conformer_{stock_symbol}_LastTrainInfo.pk', 'rb') as f:\n","            last_train_info = pickle.load(f)\n","        lr = last_train_info['lr']\n","        last_epoch = last_train_info['epoch']\n","        min_val_loss = last_train_info['min val loss']\n","        model.load_state_dict(torch.load(f'Temp//Conformer_{stock_symbol}_checkpoint_LastTrainModel.pt'))\n","        with open(f'Temp//Conformer_{stock_symbol}_TrainValHistLoss.pk', 'rb') as f:\n","            loss_train_val = pickle.load(f)\n","        loss_train = loss_train_val['train']\n","        loss_valid = loss_train_val['valid']\n","else:\n","    print(\"Init model\")\n","    lr = lr\n","    last_epoch = 0\n","    min_val_loss = 10000.0\n","    loss_train = []\n","    loss_valid = []\n","    \n","print(f'Last train epoch: {last_epoch}  '\n","        f'Last train lr: {lr}   '\n","        f'Min val loss: {min_val_loss}')\n","\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.00001)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=len(trainloader)*5, gamma=0.9)        \n","\n","if fp16_training:\n","    print('Accelerate Prepare')    \n","    model, optimizer, trainloader, validloader, scheduler = \\\n","        accelerator.prepare(model, optimizer, trainloader, validloader, scheduler)"]},{"cell_type":"markdown","metadata":{"id":"24AwH-nhes4f"},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for epoch in range(last_epoch, num_epochs):\n","    # Training phase\n","    model.train()\n","    loss_train_e = 0\n","    for batch_x, batch_y in tqdm(trainloader):\n","        optimizer.zero_grad()\n","        outputs = model(batch_x)\n","\n","        # Loss\n","        loss = criterion(outputs, batch_y)\n","        if fp16_training:\n","            accelerator.backward(loss)\n","        else:\n","            loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        loss_train_e += loss.item()\n","        \n","    loss_train_e /= len(validloader)\n","    loss_train.append(loss_train_e)\n","    \n","    loss_valid_e = 0\n","    with torch.no_grad():\n","        model.eval()\n","        for batch_x_val, batch_y_val in tqdm(validloader):\n","            # batch_x_val = mask(batch_x_val)\n","            outputs_val = model(batch_x_val)\n","            loss = criterion(outputs_val, batch_y_val)\n","            loss_valid_e += loss.item()\n","        loss_valid_e /= len(validloader)\n","        loss_valid.append(loss_valid_e)\n","            \n","        torch.save(model.state_dict(), f'Temp/Conformer_{stock_symbol}_checkpoint_LastTrainModel.pt')\n","        if loss_valid_e < min_val_loss:\n","            min_val_loss = loss_valid_e\n","            print(f'New best model found in epoch {epoch} with val loss: {min_val_loss}')\n","            torch.save(model.state_dict(), f'ConformerResult/Conformer_{stock_symbol}_best_model.pt')            \n","        if epoch % 50 == 0:\n","            pass\n","            # torch.save(model, f'ConformerResult/Conformerr_{stock_symbol}_checkpoint_{epoch}.pt')\n","            \n","    with open(f'Temp/Conformer_{stock_symbol}_TrainValHistLoss.pk', 'wb') as f:\n","        pickle.dump({'train': loss_train, 'valid': loss_valid}, f)\n","    with open(f'Temp/Conformer_{stock_symbol}_LastTrainInfo.pk', 'wb') as f:\n","        pickle.dump({'min val loss': min_val_loss, 'epoch': epoch, 'lr': optimizer.param_groups[0]['lr']}, f)\n","        \n","    # Print statistics\n","    print(f'Epoch [{epoch}/{num_epochs}]',\n","        f'Training Loss: {loss_train_e:.10f}',\n","        f'Valid Loss: {loss_valid_e:.10f}')"]},{"cell_type":"markdown","metadata":{"id":"gdsTCRhq_a_O"},"source":["# Validate Model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1708508308097,"user":{"displayName":"Kuo Jacob","userId":"03725230422177139348"},"user_tz":-480},"id":"Xr_xzxUygrCM"},"outputs":[],"source":["def load_model():\n","    import torch\n","    model = torch.load(f'ConformerResult/Conformer_{stock_symbol}_best_model.pt')\n","    return model\n","model = load_model()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":46476,"status":"ok","timestamp":1708508354571,"user":{"displayName":"Kuo Jacob","userId":"03725230422177139348"},"user_tz":-480},"id":"-Vxhjr2bfVrJ"},"outputs":[],"source":["\n","import gc\n","def test():\n","    dataloader = dataloader_test\n","\n","    model.eval()\n","    s_pred = []\n","    s_true = []\n","    for x, y in tqdm(dataloader):\n","        y_pred = model(x)\n","        s_pred.append(y_pred.detach())\n","        s_true.append(y)\n","    y_pred_tensor = torch.concat(s_pred)\n","    y_test_tensor = torch.concat(s_true)\n","    accuracy = (torch.sign(y_pred_tensor) == torch.sign(y_test_tensor)).sum() / len(y_test_tensor)\n","    return y_pred_tensor, accuracy\n","\n","y_pred, acc = test()\n","print(acc)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18330,"status":"ok","timestamp":1708508372899,"user":{"displayName":"Kuo Jacob","userId":"03725230422177139348"},"user_tz":-480},"id":"wMKUVbcfj8zX"},"outputs":[],"source":["# Derive y_pred and y_train_pred of shape(N, 2) and numpy type\n","\n","y_pred_numpy = y_pred.cpu().numpy()\n","\n","# predict with train set\n","y_train_pred = model(torch.tensor(X[-100:], dtype = torch.float32))\n","y_train_numpy = y_train_pred.detach().cpu().numpy()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iKLtCWerEIac"},"outputs":[],"source":["import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","\n","# Scaling\n","prediction = pd.DataFrame(y_pred_numpy)\n","scaler = StandardScaler()\n","scaler.fit(y_train_numpy)\n","prediction = pd.DataFrame(scaler.transform(prediction))\n","\n","# Get the predicted price of O and C and Prediction merge with complete data\n","prediction.columns = ['pred_do_1', 'pred_dc_1']\n","prediction['Date'] = date\n","\n","true_and_pred = pd.merge(df.reset_index(), prediction, on = 'Date', how = 'left')\n","true_and_pred['pred_o'] = (true_and_pred['Open'] * (1 + true_and_pred['pred_do_1'])).shift(1)\n","true_and_pred['pred_c'] = (true_and_pred['Close'] * (1 + true_and_pred['pred_dc_1'])).shift(1)\n","true_and_pred['pred_oc'] = true_and_pred['pred_c'] - true_and_pred['pred_o']\n","true_and_pred['true_oc'] = true_and_pred['Close'] - true_and_pred['Open']\n","\n","# Backtest\n","asset_list = []\n","df_backtest = true_and_pred[['Open', 'Close', 'true_oc', 'pred_oc']].dropna()\n","asset = 1\n","for index, (o, c, true, pred) in df_backtest.iterrows():\n","    if pred > 0:\n","        returns = true/o\n","        asset *= (1 + returns)\n","    asset_list.append(asset)\n","\n","print(asset)\n","plt.plot(asset_list, label = 'resnet')\n","plt.plot(df_backtest.reset_index()['Close']/df_backtest['Close'].iloc[0], label = 'buy hold')\n","plt.legend()\n","plt.savefig('/ConformerResult/test_backtest.jpg')\n","# plt.show()"]}],"metadata":{"colab":{"collapsed_sections":["2dlPDr1feNdw","N2GtucuTfVrD","24AwH-nhes4f"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
