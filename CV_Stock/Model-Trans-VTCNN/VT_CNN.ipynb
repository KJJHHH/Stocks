{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Import and Set"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import sys\n","sys.path.append('../')\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import MinMaxScaler\n","import yfinance as yf\n","import numpy as np\n","import os\n","import pickle\n","from torchaudio.models import Conformer\n","import math\n","from torch import nn, Tensor\n","from tqdm import tqdm\n","import torch\n","import torchvision\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.preprocessing import Normalizer, StandardScaler\n","from einops.layers.torch import Rearrange, Reduce\n","from utils import *\n","from model import VT_CNN\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","num_class = 1\n","stock_symbol = '5871.TW'\n","end_date = '2024-12-31'\n","\n","init = True\n","fp16_training = False\n","num_epochs = 500\n","config = {\n","    'lr': 0.001,\n","}"]},{"cell_type":"markdown","metadata":{"id":"2dlPDr1feNdw"},"source":["# Init"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["with open('../DataLoader/dataloader.pk', 'rb') as f:\n","    data = pickle.load(f)\n","dataloader_train = data['trainloader']\n","dataloader_valid = data['validloader']\n","# dataloader_test = data['testloader']"]},{"cell_type":"markdown","metadata":{"id":"N2GtucuTfVrD"},"source":["# Define model\n","### Question\n","- Conformer include decoder?"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Vision Transformer: https://github.com/pytorch/vision/blob/main/torchvision/models/vision_transformer.py\n","# try pretrain, same link above\n","class VT_CNN(nn.Module):\n","    def __init__(self, num_class=2):\n","        super(VT_CNN, self).__init__()\n","\n","        # =======\n","        # Unet\n","        self.conv_init = nn.Conv2d(5, 3, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.VisionTransformer = torchvision.models.VisionTransformer(\n","            image_size = 100,\n","            patch_size = 10,\n","            num_layers = 16,\n","            num_heads = 5,\n","            hidden_dim = 250,\n","            mlp_dim = 520\n","        )\n","        self.ln_init = nn.LayerNorm(1000)\n","        self.fc = nn.Linear(1000, num_class)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Input scale: (0, 255)\n","        Output scale: (0, 255)\n","        \"\"\"\n","        \n","        x = self.conv_init(x)\n","        x = self.VisionTransformer(x)\n","        x = self.ln_init(x)\n","        x = self.relu(x)        \n","        x = self.fc(x)\n","\n","        return x\n","    "]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["'\\nx = 123\\ndef global_var():\\n    global x\\n    x = \"awesome\"\\n    print(x)\\nprint(x)\\nglobal_var()\\n'"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","x = 123\n","def global_var():\n","    global x\n","    x = \"awesome\"\n","    print(x)\n","print(x)\n","global_var()\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"24AwH-nhes4f"},"source":["# Train"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Init model\n","Last train epoch: 0  Last train lr: 0.001   Min val loss: 10000\n"]}],"source":["\"\"\"\n","Choose if fp16 and define model\n","\"\"\"\n","# !pip install accelerate==0.2.0\n","# Model\n","if fp16_training:\n","    print('Accelerating')\n","    from accelerate import Accelerator\n","    accelerator = Accelerator(fp16=True)\n","    device = accelerator.device\n","    model = VT_CNN()\n","else:\n","    model = VT_CNN().to(device)\n","\n","\"\"\"\n","Init for models, learning rate, ...\n","\"\"\"\n","if os.path.exists(f'Temp//Conformer_{stock_symbol}_LastTrainInfo.pk'):\n","    if init:\n","        print(\"Init model\")\n","        lr = config['lr']\n","        last_epoch = 0\n","        min_val_loss = 10000\n","        loss_train = []\n","        loss_valid = []\n","    else:\n","        print('Load from last train epoch')\n","        with open(f'Temp//Conformer_{stock_symbol}_LastTrainInfo.pk', 'rb') as f:\n","            last_train_info = pickle.load(f)\n","        lr = last_train_info['lr']\n","        last_epoch = last_train_info['epoch']\n","        min_val_loss = last_train_info['min val loss']\n","        model.load_state_dict(torch.load(f'Temp//Conformer_{stock_symbol}_checkpoint_LastTrainModel.pt'))\n","        with open(f'Temp//Conformer_{stock_symbol}_TrainValHistLoss.pk', 'rb') as f:\n","            loss_train_val = pickle.load(f)\n","        loss_train = loss_train_val['train']\n","        loss_valid = loss_train_val['valid']\n","else:\n","    print(\"Init model\")\n","    lr = config['lr']\n","    last_epoch = 0\n","    min_val_loss = 10000.0\n","    loss_train = []\n","    loss_valid = []\n","print(f'Last train epoch: {last_epoch}  '\n","        f'Last train lr: {lr}   '\n","        f'Min val loss: {min_val_loss}')\n","\n","import torch.optim as optim\n","import pickle\n","\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.00001)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=len(dataloader_train)*10, gamma=0.9)        \n","\n","# Prepare\n","if fp16_training:\n","    print('Accelerate Prepare')    \n","    model, optimizer, dataloader_train, dataloader_valid, scheduler = \\\n","        accelerator.prepare(model, optimizer, dataloader_train, dataloader_valid, scheduler)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/65 [00:00<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:08<00:00,  7.23it/s]\n","100%|██████████| 17/17 [00:00<00:00, 24.35it/s]\n","  0%|          | 0/65 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["New best model found in epoch 0 with val loss: 0.0013352816801189499\n","Epoch [0/500] Training Loss: 3.4953858183 Valid Loss: 0.0013352817\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:08<00:00,  7.99it/s]\n","100%|██████████| 17/17 [00:00<00:00, 24.94it/s]\n","  2%|▏         | 1/65 [00:00<00:07,  8.00it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/500] Training Loss: 3.4907736540 Valid Loss: 0.0023617290\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:08<00:00,  7.86it/s]\n","100%|██████████| 17/17 [00:00<00:00, 24.68it/s]\n","  2%|▏         | 1/65 [00:00<00:07,  8.08it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/500] Training Loss: 3.4876863420 Valid Loss: 0.0036947462\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:08<00:00,  7.88it/s]\n","100%|██████████| 17/17 [00:00<00:00, 23.12it/s]\n","  2%|▏         | 1/65 [00:00<00:08,  7.91it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/500] Training Loss: 3.4855152974 Valid Loss: 0.0051539265\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:08<00:00,  7.75it/s]\n","100%|██████████| 17/17 [00:00<00:00, 24.11it/s]\n","  2%|▏         | 1/65 [00:00<00:08,  7.62it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/500] Training Loss: 3.4839747521 Valid Loss: 0.0066259813\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:09<00:00,  7.10it/s]\n","100%|██████████| 17/17 [00:00<00:00, 23.78it/s]\n","  2%|▏         | 1/65 [00:00<00:08,  7.72it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/500] Training Loss: 3.4828795878 Valid Loss: 0.0080413789\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:08<00:00,  7.92it/s]\n","100%|██████████| 17/17 [00:00<00:00, 24.44it/s]\n","  2%|▏         | 1/65 [00:00<00:08,  7.90it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [6/500] Training Loss: 3.4821012625 Valid Loss: 0.0093601216\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:08<00:00,  7.86it/s]\n","100%|██████████| 17/17 [00:00<00:00, 24.42it/s]\n","  2%|▏         | 1/65 [00:00<00:07,  8.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [7/500] Training Loss: 3.4815484886 Valid Loss: 0.0105620098\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:08<00:00,  7.92it/s]\n","100%|██████████| 17/17 [00:00<00:00, 24.65it/s]\n","  2%|▏         | 1/65 [00:00<00:08,  7.62it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [8/500] Training Loss: 3.4811566101 Valid Loss: 0.0116398565\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:08<00:00,  7.88it/s]\n","100%|██████████| 17/17 [00:00<00:00, 23.44it/s]\n","  2%|▏         | 1/65 [00:00<00:07,  8.04it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [9/500] Training Loss: 3.4808790913 Valid Loss: 0.0125947480\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:08<00:00,  7.84it/s]\n","100%|██████████| 17/17 [00:00<00:00, 24.59it/s]\n","  2%|▏         | 1/65 [00:00<00:07,  8.02it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [10/500] Training Loss: 3.4806626682 Valid Loss: 0.0133592464\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:08<00:00,  7.79it/s]\n","100%|██████████| 17/17 [00:00<00:00, 24.91it/s]\n","  2%|▏         | 1/65 [00:00<00:08,  7.93it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [11/500] Training Loss: 3.4805311075 Valid Loss: 0.0140351903\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:08<00:00,  7.86it/s]\n","100%|██████████| 17/17 [00:00<00:00, 24.35it/s]\n","  2%|▏         | 1/65 [00:00<00:07,  8.02it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [12/500] Training Loss: 3.4804349936 Valid Loss: 0.0146299973\n"]},{"name":"stderr","output_type":"stream","text":[" 65%|██████▍   | 42/65 [00:05<00:03,  7.48it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     20\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 21\u001b[0m     loss_train_e \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m loss_train_e \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader_train)\n\u001b[1;32m     24\u001b[0m loss_train\u001b[38;5;241m.\u001b[39mappend(loss_train_e)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["for epoch in range(last_epoch, num_epochs):\n","    # Training phase\n","    model.train()\n","    loss_train_e = 0\n","    for batch_x, batch_y in tqdm(dataloader_train):\n","        # batch_x = mask(batch_x)\n","        if not fp16_training:\n","            batch_x = batch_x.to(device)\n","            batch_y = batch_y.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(batch_x)\n","\n","        # Loss\n","        loss = criterion(outputs, batch_y*100)\n","        if fp16_training:\n","            accelerator.backward(loss)\n","        else:\n","            loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        loss_train_e += loss.item()\n","        \n","    loss_train_e /= len(dataloader_train)\n","    loss_train.append(loss_train_e)\n","    \n","    loss_valid_e = 0\n","    with torch.no_grad():\n","        model.eval()\n","        for batch_x_val, batch_y_val in tqdm(dataloader_valid):\n","            # batch_x_val = mask(batch_x_val)\n","            if not fp16_training:\n","                batch_x_val = batch_x_val.to(device)\n","                batch_y_val = batch_y_val.to(device)\n","            outputs_val = model(batch_x_val)\n","            loss = criterion(outputs_val, batch_y_val)\n","            loss_valid_e += loss.item()\n","        loss_valid_e /= len(dataloader_valid)\n","        loss_valid.append(loss_valid_e)\n","            \n","        torch.save(model.state_dict(), f'Temp/Conformer_{stock_symbol}_checkpoint_LastTrainModel.pt')\n","        if loss_valid_e < min_val_loss:\n","            min_val_loss = loss_valid_e\n","            print(f'New best model found in epoch {epoch} with val loss: {min_val_loss}')\n","            torch.save(model.state_dict(), f'ConformerResult/Conformer_{stock_symbol}_best_model.pt')            \n","        if epoch % 50 == 0:\n","            pass\n","            # torch.save(model, f'ConformerResult/Conformerr_{stock_symbol}_checkpoint_{epoch}.pt')\n","            \n","    with open(f'Temp/Conformer_{stock_symbol}_TrainValHistLoss.pk', 'wb') as f:\n","        pickle.dump({'train': loss_train, 'valid': loss_valid}, f)\n","    with open(f'Temp/Conformer_{stock_symbol}_LastTrainInfo.pk', 'wb') as f:\n","        pickle.dump({'min val loss': min_val_loss, 'epoch': epoch, 'lr': optimizer.param_groups[0]['lr']}, f)\n","        \n","    # Print statistics\n","    print(f'Epoch [{epoch}/{num_epochs}]',\n","        f'Training Loss: {loss_train_e:.10f}',\n","        f'Valid Loss: {loss_valid_e:.10f}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["(torch.Size([32, 1]), torch.Size([32, 1]))"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["outputs.shape, batch_y.shape"]},{"cell_type":"markdown","metadata":{"id":"gdsTCRhq_a_O"},"source":["# Validate Model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1708508308097,"user":{"displayName":"Kuo Jacob","userId":"03725230422177139348"},"user_tz":-480},"id":"Xr_xzxUygrCM"},"outputs":[],"source":["def load_model():\n","    import torch\n","    model = torch.load(f'ConformerResult/Conformer_{stock_symbol}_best_model.pt')\n","    return model\n","model = load_model()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":46476,"status":"ok","timestamp":1708508354571,"user":{"displayName":"Kuo Jacob","userId":"03725230422177139348"},"user_tz":-480},"id":"-Vxhjr2bfVrJ"},"outputs":[],"source":["\n","import gc\n","def test():\n","    dataloader = dataloader_test\n","\n","    model.eval()\n","    s_pred = []\n","    s_true = []\n","    for x, y in tqdm(dataloader):\n","        y_pred = model(x)\n","        s_pred.append(y_pred.detach())\n","        s_true.append(y)\n","    y_pred_tensor = torch.concat(s_pred)\n","    y_test_tensor = torch.concat(s_true)\n","    accuracy = (torch.sign(y_pred_tensor) == torch.sign(y_test_tensor)).sum() / len(y_test_tensor)\n","    return y_pred_tensor, accuracy\n","\n","y_pred, acc = test()\n","print(acc)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18330,"status":"ok","timestamp":1708508372899,"user":{"displayName":"Kuo Jacob","userId":"03725230422177139348"},"user_tz":-480},"id":"wMKUVbcfj8zX"},"outputs":[],"source":["# Derive y_pred and y_train_pred of shape(N, 2) and numpy type\n","\n","y_pred_numpy = y_pred.cpu().numpy()\n","\n","# predict with train set\n","y_train_pred = model(torch.tensor(X[-100:], dtype = torch.float32))\n","y_train_numpy = y_train_pred.detach().cpu().numpy()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iKLtCWerEIac"},"outputs":[],"source":["import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","\n","# Scaling\n","prediction = pd.DataFrame(y_pred_numpy)\n","scaler = StandardScaler()\n","scaler.fit(y_train_numpy)\n","prediction = pd.DataFrame(scaler.transform(prediction))\n","\n","# Get the predicted price of O and C and Prediction merge with complete data\n","prediction.columns = ['pred_do_1', 'pred_dc_1']\n","prediction['Date'] = date\n","\n","true_and_pred = pd.merge(df.reset_index(), prediction, on = 'Date', how = 'left')\n","true_and_pred['pred_o'] = (true_and_pred['Open'] * (1 + true_and_pred['pred_do_1'])).shift(1)\n","true_and_pred['pred_c'] = (true_and_pred['Close'] * (1 + true_and_pred['pred_dc_1'])).shift(1)\n","true_and_pred['pred_oc'] = true_and_pred['pred_c'] - true_and_pred['pred_o']\n","true_and_pred['true_oc'] = true_and_pred['Close'] - true_and_pred['Open']\n","\n","# Backtest\n","asset_list = []\n","df_backtest = true_and_pred[['Open', 'Close', 'true_oc', 'pred_oc']].dropna()\n","asset = 1\n","for index, (o, c, true, pred) in df_backtest.iterrows():\n","    if pred > 0:\n","        returns = true/o\n","        asset *= (1 + returns)\n","    asset_list.append(asset)\n","\n","print(asset)\n","plt.plot(asset_list, label = 'resnet')\n","plt.plot(df_backtest.reset_index()['Close']/df_backtest['Close'].iloc[0], label = 'buy hold')\n","plt.legend()\n","plt.savefig('/ConformerResult/test_backtest.jpg')\n","# plt.show()"]}],"metadata":{"colab":{"collapsed_sections":["2dlPDr1feNdw","N2GtucuTfVrD","24AwH-nhes4f"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
