{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import sys\n","sys.path.append('../')\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import MinMaxScaler\n","import yfinance as yf\n","import numpy as np\n","import os\n","import pickle\n","from tqdm import tqdm\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.preprocessing import Normalizer, StandardScaler\n","from utils import *\n","from models.ConformerCNN import Conformer_CNN\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","num_class = 2\n","stock_symbol = '5871.TW'\n","end_date = '2024-12-31'\n","init = True\n","lr = 0.001\n","num_epochs = 500"]},{"cell_type":"markdown","metadata":{"id":"2dlPDr1feNdw"},"source":["# Data"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["if num_class == 1:\n","    with open('../DataLoader/dataloader_1.pk', 'rb') as f:\n","        data = pickle.load(f)\n","    dataloader_train = data['trainloader']\n","    dataloader_valid = data['validloader']\n","else:\n","    with open('../DataLoader/dataloader.pk', 'rb') as f:\n","        data = pickle.load(f)\n","    dataloader_train = data['trainloader']\n","    dataloader_valid = data['validloader']"]},{"cell_type":"markdown","metadata":{"id":"24AwH-nhes4f"},"source":["# Model and Setting"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Init model\n","Last train epoch: 0  Last train lr: 0.001   Min val loss: 10000.0\n"]}],"source":["fp16_training = False\n","if fp16_training:\n","    from accelerate import Accelerator\n","    accelerator = Accelerator()\n","    device = accelerator.device\n","    model = Conformer_CNN(num_class)\n","else:\n","    model = Conformer_CNN(num_class).to(device)\n","Model = model.model_type\n","\n","if os.path.exists(f'Temp//{Model}_class{num_class}_{stock_symbol}_LastTrainInfo.pk'):\n","    if init:\n","        print(\"Init model\")\n","        lr = lr\n","        last_epoch = 0\n","        min_val_loss = 10000.0\n","        loss_train = []\n","        loss_valid = []\n","    else:\n","        print('Load from last train epoch')\n","        with open(f'Temp//{Model}_class{num_class}_{stock_symbol}_LastTrainInfo.pk', 'rb') as f:\n","            last_train_info = pickle.load(f)\n","        lr = last_train_info['lr']\n","        last_epoch = last_train_info['epoch']\n","        min_val_loss = last_train_info['min val loss']\n","        model.load_state_dict(torch.load(f'Temp//{Model}_class{num_class}_{stock_symbol}_checkpoint_LastTrainModel.pt'))\n","        with open(f'Temp//{Model}_class{num_class}_{stock_symbol}_TrainValHistLoss.pk', 'rb') as f:\n","            loss_train_val = pickle.load(f)\n","        loss_train = loss_train_val['train']\n","        loss_valid = loss_train_val['valid']\n","else:\n","    print(\"Init model\")\n","    lr = lr\n","    last_epoch = 0\n","    min_val_loss = 10000.0\n","    loss_train = []\n","    loss_valid = []\n","print(f'Last train epoch: {last_epoch}  '\n","        f'Last train lr: {lr}   '\n","        f'Min val loss: {min_val_loss}')\n","\n","import torch.optim as optim\n","import pickle\n","\n","# Instantiate the model\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.00001)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=len(dataloader_train)*5, gamma=0.9\n","                                      )        \n","\n","if fp16_training:\n","    model, optimizer, dataloader_train, dataloader_valid = \\\n","        accelerator.prepare(model, optimizer, dataloader_train, dataloader_valid)"]},{"cell_type":"markdown","metadata":{},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mFVOcQXhfVrH"},"outputs":[],"source":["for epoch in range(last_epoch, num_epochs):\n","    # Training phase\n","    model.train()\n","    loss_train_e = 0\n","    for batch_x, batch_y in tqdm(dataloader_train):\n","        batch_x = batch_x.to(device)\n","        batch_y = batch_y.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(batch_x)\n","\n","        loss = criterion(outputs, batch_y)\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        loss_train_e += loss.item()\n","    loss_train_e /= len(dataloader_train)\n","    loss_train.append(loss_train_e)\n","    \n","    loss_valid_e = 0\n","    with torch.no_grad():\n","        model.eval()\n","        for batch_x_val, batch_y_val in tqdm(dataloader_valid):\n","            batch_x_val = batch_x_val.to(device)\n","            batch_y_val = batch_y_val.to(device)\n","            outputs_val = model(batch_x_val)\n","            loss = criterion(outputs_val, batch_y_val)\n","            loss_valid_e += loss.item()\n","        loss_valid_e /= len(dataloader_valid)\n","        loss_valid.append(loss_valid_e)\n","            \n","        torch.save(model.state_dict(), f'Temp/{Model}_class{num_class}_{stock_symbol}_checkpoint_LastTrainModel.pt')\n","        if loss_valid_e < min_val_loss:\n","            min_val_loss = loss_valid_e\n","            print(f'New best model found in epoch {epoch} with val loss: {min_val_loss}')\n","            torch.save(model.state_dict(), f'Result/{Model}_class{num_class}_{stock_symbol}_best_model.pt')            \n","        if epoch % 50 == 0:\n","            pass\n","            # torch.save(model, f'ConformerResult/Conformerr_{stock_symbol}_checkpoint_{epoch}.pt')\n","            \n","    with open(f'Temp/{Model}_class{num_class}_{stock_symbol}_TrainValHistLoss.pk', 'wb') as f:\n","        pickle.dump({'train': loss_train, 'valid': loss_valid}, f)\n","    with open(f'Temp/{Model}_class{num_class}_{stock_symbol}_LastTrainInfo.pk', 'wb') as f:\n","        pickle.dump({'min val loss': min_val_loss, 'epoch': epoch, 'lr': optimizer.param_groups[0]['lr']}, f)\n","        \n","    # Print statistics\n","    print(f'Epoch [{epoch}/{num_epochs}]',\n","        f'Training Loss: {loss_train_e:.10f}',\n","        f'Valid Loss: {loss_valid_e:.10f}')\n"]},{"cell_type":"markdown","metadata":{"id":"gdsTCRhq_a_O"},"source":["# Validate Model"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1708508308097,"user":{"displayName":"Kuo Jacob","userId":"03725230422177139348"},"user_tz":-480},"id":"Xr_xzxUygrCM"},"outputs":[],"source":["def load_model():\n","    import torch\n","    model = torch.load(f'ConformerResult/Conformer_{stock_symbol}_best_model.pt')\n","    return model\n","model = load_model()"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":46476,"status":"ok","timestamp":1708508354571,"user":{"displayName":"Kuo Jacob","userId":"03725230422177139348"},"user_tz":-480},"id":"-Vxhjr2bfVrJ"},"outputs":[{"ename":"NameError","evalue":"name 'dataloader_test' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39msign(y_pred_tensor) \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39msign(y_test_tensor))\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(y_test_tensor)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y_pred_tensor, accuracy\n\u001b[0;32m---> 17\u001b[0m y_pred, acc \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(acc)\n","Cell \u001b[0;32mIn[6], line 3\u001b[0m, in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest\u001b[39m():\n\u001b[0;32m----> 3\u001b[0m     dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mdataloader_test\u001b[49m\n\u001b[1;32m      5\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      6\u001b[0m     s_pred \u001b[38;5;241m=\u001b[39m []\n","\u001b[0;31mNameError\u001b[0m: name 'dataloader_test' is not defined"]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n","\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n","\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["\n","import gc\n","def test():\n","    dataloader = dataloader_test\n","\n","    model.eval()\n","    s_pred = []\n","    s_true = []\n","    for x, y in tqdm(dataloader):\n","        y_pred = model(x)\n","        s_pred.append(y_pred.detach())\n","        s_true.append(y)\n","    y_pred_tensor = torch.concat(s_pred)\n","    y_test_tensor = torch.concat(s_true)\n","    accuracy = (torch.sign(y_pred_tensor) == torch.sign(y_test_tensor)).sum() / len(y_test_tensor)\n","    return y_pred_tensor, accuracy\n","\n","y_pred, acc = test()\n","print(acc)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18330,"status":"ok","timestamp":1708508372899,"user":{"displayName":"Kuo Jacob","userId":"03725230422177139348"},"user_tz":-480},"id":"wMKUVbcfj8zX"},"outputs":[],"source":["# Derive y_pred and y_train_pred of shape(N, 2) and numpy type\n","\n","y_pred_numpy = y_pred.cpu().numpy()\n","\n","# predict with train set\n","y_train_pred = model(torch.tensor(X[-100:], dtype = torch.float32))\n","y_train_numpy = y_train_pred.detach().cpu().numpy()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iKLtCWerEIac"},"outputs":[],"source":["import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","\n","# Scaling\n","prediction = pd.DataFrame(y_pred_numpy)\n","scaler = StandardScaler()\n","scaler.fit(y_train_numpy)\n","prediction = pd.DataFrame(scaler.transform(prediction))\n","\n","# Get the predicted price of O and C and Prediction merge with complete data\n","prediction.columns = ['pred_do_1', 'pred_dc_1']\n","prediction['Date'] = date\n","\n","true_and_pred = pd.merge(df.reset_index(), prediction, on = 'Date', how = 'left')\n","true_and_pred['pred_o'] = (true_and_pred['Open'] * (1 + true_and_pred['pred_do_1'])).shift(1)\n","true_and_pred['pred_c'] = (true_and_pred['Close'] * (1 + true_and_pred['pred_dc_1'])).shift(1)\n","true_and_pred['pred_oc'] = true_and_pred['pred_c'] - true_and_pred['pred_o']\n","true_and_pred['true_oc'] = true_and_pred['Close'] - true_and_pred['Open']\n","\n","# Backtest\n","asset_list = []\n","df_backtest = true_and_pred[['Open', 'Close', 'true_oc', 'pred_oc']].dropna()\n","asset = 1\n","for index, (o, c, true, pred) in df_backtest.iterrows():\n","    if pred > 0:\n","        returns = true/o\n","        asset *= (1 + returns)\n","    asset_list.append(asset)\n","\n","print(asset)\n","plt.plot(asset_list, label = 'resnet')\n","plt.plot(df_backtest.reset_index()['Close']/df_backtest['Close'].iloc[0], label = 'buy hold')\n","plt.legend()\n","plt.savefig('/ConformerResult/test_backtest.jpg')\n","# plt.show()"]}],"metadata":{"colab":{"collapsed_sections":["2dlPDr1feNdw","N2GtucuTfVrD","24AwH-nhes4f"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
