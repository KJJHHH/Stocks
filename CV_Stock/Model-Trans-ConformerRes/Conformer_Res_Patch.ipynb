{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import sys\n","sys.path.append('../')\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import MinMaxScaler\n","import yfinance as yf\n","import numpy as np\n","import os\n","import pickle\n","from torchaudio.models import Conformer\n","import math\n","from torch import nn, Tensor\n","from tqdm import tqdm\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.preprocessing import Normalizer, StandardScaler\n","from einops.layers.torch import Rearrange, Reduce\n","from utils import *\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","num_class = 2\n","stock_symbol = '5871.TW'\n","end_date = '2024-12-31'\n","init = False"]},{"cell_type":"markdown","metadata":{"id":"2dlPDr1feNdw"},"source":["# Init"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with open('../DataLoader/dataloader.pk', 'rb') as f:\n","    data = pickle.load(f)\n","dataloader_train = data['trainloader']\n","dataloader_valid = data['validloader']\n","# dataloader_test = data['testloader']"]},{"cell_type":"markdown","metadata":{"id":"N2GtucuTfVrD"},"source":["# Define model\n","### Question\n","- Conformer include decoder?"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1477,"status":"ok","timestamp":1708508307622,"user":{"displayName":"Kuo Jacob","userId":"03725230422177139348"},"user_tz":-480},"id":"bBbKgszAfVrF"},"outputs":[],"source":["# https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n","class PositionalEncoding(nn.Module):\n","\n","    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n","        super().__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        position = torch.arange(max_len).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n","        pe = torch.zeros(max_len, 1, d_model)\n","        pe[:, 0, 0::2] = torch.sin(position * div_term)\n","        pe[:, 0, 1::2] = torch.cos(position * div_term)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x: Tensor) -> Tensor:\n","        \"\"\"\n","        Arguments:\n","            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n","        \"\"\"\n","        x = x + self.pe[:x.size(0)]\n","        return self.dropout(x)\n","\n","# https://zhuanlan.zhihu.com/p/348849092\n","class PatchEmbedding(nn.Module):\n","    def __init__(self, in_channels: int = 3, patch_size: int = 16, emb_size: int = 768):\n","        self.patch_size = patch_size\n","        super().__init__()\n","        self.projection = nn.Sequential(\n","            # 在s1 x s2切片中分解图像并将其平面化\n","            Rearrange('b c (h s1) (w s2) -> b (h w) (s1 s2 c)', s1=patch_size, s2=patch_size),\n","            nn.Linear(patch_size * patch_size * in_channels, emb_size)\n","        )\n","                \n","    def forward(self, x: Tensor) -> Tensor:\n","        x = self.projection(x)\n","        return x\n","\n","# Resnet from Pytorch: https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py\n","# Resnet pretrain pytorch: https://pytorch.org/hub/pytorch_vision_resnet/\n","# https://medium.com/ching-i/%E5%8D%B7%E7%A9%8D%E7%A5%9E%E7%B6%93%E7%B6%B2%E7%B5%A1-cnn-%E7%B6%93%E5%85%B8%E6%A8%A1%E5%9E%8B-googlelenet-resnet-densenet-with-pytorch-code-1688015808d9\n","class bottleneck_block(nn.Module):\n","    # 輸出通道乘的倍數\n","    expansion = 4\n","\n","    def __init__(self, in_channels, out_channels, stride, downsample):\n","        super(bottleneck_block, self).__init__()      \n","        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","        self.conv3 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels * self.expansion, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n","\n","        # 在 shortcut 時，若維度不一樣，要更改維度\n","        self.downsample = downsample \n","\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out\n","    \n","class Res_Conformer_Unet(nn.Module):\n","    def __init__(self, net_block, layers, num_class, conformer = False, res = True):\n","        super(Res_Conformer_Unet, self).__init__()\n","\n","        # =======\n","        # Unet\n","        self.in_channels = 64\n","        self.conv1 = nn.Conv2d(in_channels=5, out_channels=64, kernel_size=7, stride=2, padding=3, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpooling = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","\n","        self.layer1 = self.net_block_layer(net_block, 64, layers[0])\n","        self.layer2 = self.net_block_layer(net_block, 128, layers[1], stride=2)\n","        self.layer3 = self.net_block_layer(net_block, 256, layers[2], stride=2)\n","        self.layer4 = self.net_block_layer(net_block, 512, layers[3], stride=2)\n","        \n","        self.avgpooling = nn.AvgPool2d(3, stride=1)        \n","        self.relu = nn.ReLU()\n","        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n","        \n","        self.fc1 = nn.Linear(2048*2*2, 128)\n","        self.fc2 = nn.Linear(128, num_class)\n","        self.ln1 = nn.LayerNorm((5, 100, 100))\n","        \n","        \n","        # =======\n","        # Conformer\n","        self.positional_encode = PositionalEncoding(100)\n","        self.patch_embedding = PatchEmbedding(in_channels=5, patch_size=10, emb_size=500)\n","        self.conformer = Conformer(\n","            input_dim=500,\n","            num_heads=5,\n","            ffn_dim=128,\n","            num_layers=6,\n","            depthwise_conv_kernel_size=31)\n","\n","\n","    def net_block_layer(self, net_block, out_channels, num_blocks, stride=1):\n","        downsample = None\n","\n","      # 在 shortcut 時，若維度不一樣，要更改維度\n","        if stride != 1 or self.in_channels != out_channels * net_block.expansion:\n","            downsample = nn.Sequential(nn.Conv2d(self.in_channels, out_channels * net_block.expansion, kernel_size=1, stride=stride, bias=False),\n","                      nn.BatchNorm2d(out_channels * net_block.expansion))\n","\n","        layers = []\n","        layers.append(net_block(self.in_channels, out_channels, stride, downsample))\n","        if net_block.expansion != 1:\n","            self.in_channels = out_channels * net_block.expansion\n","        else:\n","            self.in_channels = out_channels\n","\n","        for i in range(1, num_blocks):\n","            layers.append(net_block(self.in_channels, out_channels, 1, None))\n","\n","        return nn.Sequential(*layers)\n","    \n","    def forward(self, x):\n","        \"\"\"\n","        Input scale: (0, 255)\n","        Output scale: (0, 255)\n","        \"\"\"\n","        \n","        x_i = x.clone()\n","        x_s = x.size()\n","        # =======\n","        # Conformer\n","        # x = x.view(x_s[0], x_s[1] * x_s[3], x_s[2])        \n","        # x = self.positional_encode(x)\n","        x = self.patch_embedding(x)\n","        lengths = torch.tensor([x.shape[1] for i in range(len(x))]).to(device)\n","        x, len_ = self.conformer(x, lengths)\n","        x = x.permute(0, 2, 1).view(x_s)\n","        \n","        x = self.ln1(x)\n","        x = x + x_i\n","        \n","        # =======\n","        # Res\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpooling(x)\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        x = self.avgpooling(x)\n","        x = x.view(x.size(0), -1)  # Flatten the tensor\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","\n","        return x\n","\n"]},{"cell_type":"markdown","metadata":{"id":"24AwH-nhes4f"},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["'\\nx = 123\\ndef global_var():\\n    global x\\n    x = \"awesome\"\\n    print(x)\\nprint(x)\\nglobal_var()\\n'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# !pip install accelerate==0.2.0\n","fp16_training = False\n","\n","if fp16_training:\n","    print('Accelerating')\n","    from accelerate import Accelerator\n","    accelerator = Accelerator(fp16=True)\n","    device = accelerator.device   \n","    # Instantiate the model\n","    model = Res_Conformer_Unet(bottleneck_block, [3, 4, 23, 3], num_class)\n","else:\n","    model = Res_Conformer_Unet(bottleneck_block, [3, 4, 23, 3], num_class).to(device)\n","\n","\"\"\"\n","x = 123\n","def global_var():\n","    global x\n","    x = \"awesome\"\n","    print(x)\n","print(x)\n","global_var()\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Load from last train epoch\n","Last train epoch: 313  Last train lr: 5.233476330273609e-05   Min val loss: 0.00047581135945887686\n"]}],"source":["if os.path.exists(f'Temp//Conformer_{stock_symbol}_LastTrainInfo.pk'):\n","    if init:\n","        print(\"Init model\")\n","        lr = 0.001\n","        last_epoch = 0\n","        min_val_loss = 10000.0\n","        loss_train = []\n","        loss_valid = []\n","    else:\n","        print('Load from last train epoch')\n","        with open(f'Temp//Conformer_{stock_symbol}_LastTrainInfo.pk', 'rb') as f:\n","            last_train_info = pickle.load(f)\n","        lr = last_train_info['lr']\n","        last_epoch = last_train_info['epoch']\n","        min_val_loss = last_train_info['min val loss']\n","        model.load_state_dict(torch.load(f'Temp//Conformer_{stock_symbol}_checkpoint_LastTrainModel.pt'))\n","        with open(f'Temp//Conformer_{stock_symbol}_TrainValHistLoss.pk', 'rb') as f:\n","            loss_train_val = pickle.load(f)\n","        loss_train = loss_train_val['train']\n","        loss_valid = loss_train_val['valid']\n","else:\n","    print(\"Init model\")\n","    lr = 0.001\n","    last_epoch = 0\n","    min_val_loss = 10000.0\n","    loss_train = []\n","    loss_valid = []\n","    \n","print(f'Last train epoch: {last_epoch}  '\n","        f'Last train lr: {lr}   '\n","        f'Min val loss: {min_val_loss}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:52<00:00,  1.25it/s]\n","100%|██████████| 17/17 [00:03<00:00,  4.37it/s]\n","  0%|          | 0/65 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [338/1500] Training Loss: 0.0000400423 Valid Loss: 0.0005468423\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:52<00:00,  1.23it/s]\n","100%|██████████| 17/17 [00:03<00:00,  4.54it/s]\n","  0%|          | 0/65 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [339/1500] Training Loss: 0.0000600113 Valid Loss: 0.0041233692\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:52<00:00,  1.24it/s]\n","100%|██████████| 17/17 [00:03<00:00,  4.34it/s]\n","  0%|          | 0/65 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [340/1500] Training Loss: 0.0000487394 Valid Loss: 0.0006000285\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:52<00:00,  1.24it/s]\n","100%|██████████| 17/17 [00:03<00:00,  4.47it/s]\n","  0%|          | 0/65 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [341/1500] Training Loss: 0.0000408137 Valid Loss: 0.0005676172\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:52<00:00,  1.24it/s]\n","100%|██████████| 17/17 [00:03<00:00,  4.52it/s]\n","  0%|          | 0/65 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [342/1500] Training Loss: 0.0000414890 Valid Loss: 0.0005707909\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:52<00:00,  1.25it/s]\n","100%|██████████| 17/17 [00:03<00:00,  4.85it/s]\n","  0%|          | 0/65 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [343/1500] Training Loss: 0.0000346739 Valid Loss: 0.0005721856\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:52<00:00,  1.23it/s]\n","100%|██████████| 17/17 [00:03<00:00,  4.29it/s]\n","  0%|          | 0/65 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [344/1500] Training Loss: 0.0000384841 Valid Loss: 0.0005602012\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:52<00:00,  1.24it/s]\n","100%|██████████| 17/17 [00:03<00:00,  4.50it/s]\n","  0%|          | 0/65 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [345/1500] Training Loss: 0.0000413994 Valid Loss: 0.0005465189\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:52<00:00,  1.24it/s]\n","100%|██████████| 17/17 [00:03<00:00,  4.45it/s]\n","  0%|          | 0/65 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [346/1500] Training Loss: 0.0000443283 Valid Loss: 0.0005301988\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:51<00:00,  1.26it/s]\n","100%|██████████| 17/17 [00:03<00:00,  4.64it/s]\n","  0%|          | 0/65 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [347/1500] Training Loss: 0.0000369518 Valid Loss: 0.0005443810\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:51<00:00,  1.26it/s]\n","100%|██████████| 17/17 [00:03<00:00,  4.43it/s]\n","  0%|          | 0/65 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [348/1500] Training Loss: 0.0000312582 Valid Loss: 0.0005713375\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:51<00:00,  1.26it/s]\n","100%|██████████| 17/17 [00:03<00:00,  4.51it/s]\n","  0%|          | 0/65 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [349/1500] Training Loss: 0.0000265447 Valid Loss: 0.0005611502\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:51<00:00,  1.27it/s]\n","100%|██████████| 17/17 [00:03<00:00,  4.74it/s]\n","  0%|          | 0/65 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [350/1500] Training Loss: 0.0000252316 Valid Loss: 0.0005667273\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:51<00:00,  1.27it/s]\n","100%|██████████| 17/17 [00:03<00:00,  4.41it/s]\n","  0%|          | 0/65 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [351/1500] Training Loss: 0.0000251860 Valid Loss: 0.0005546615\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:51<00:00,  1.26it/s]\n","100%|██████████| 17/17 [00:03<00:00,  4.72it/s]\n","  0%|          | 0/65 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [352/1500] Training Loss: 0.0000258081 Valid Loss: 0.0005465441\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:51<00:00,  1.27it/s]\n","100%|██████████| 17/17 [00:03<00:00,  4.39it/s]\n","  0%|          | 0/65 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [353/1500] Training Loss: 0.0000219461 Valid Loss: 0.0005306587\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:51<00:00,  1.27it/s]\n","100%|██████████| 17/17 [00:03<00:00,  4.77it/s]\n","  0%|          | 0/65 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [354/1500] Training Loss: 0.0000278400 Valid Loss: 0.0005320241\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:51<00:00,  1.26it/s]\n","100%|██████████| 17/17 [00:03<00:00,  4.63it/s]\n","  0%|          | 0/65 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [355/1500] Training Loss: 0.0000292094 Valid Loss: 0.0005381836\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:51<00:00,  1.26it/s]\n","100%|██████████| 17/17 [00:03<00:00,  4.83it/s]\n","  0%|          | 0/65 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [356/1500] Training Loss: 0.0000205073 Valid Loss: 0.0005410817\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:52<00:00,  1.25it/s]\n","100%|██████████| 17/17 [00:03<00:00,  4.67it/s]\n","  0%|          | 0/65 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [357/1500] Training Loss: 0.0000164997 Valid Loss: 0.0005400705\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:52<00:00,  1.24it/s]\n","100%|██████████| 17/17 [00:03<00:00,  4.46it/s]\n","  0%|          | 0/65 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [358/1500] Training Loss: 0.0000193876 Valid Loss: 0.0005470220\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:52<00:00,  1.24it/s]\n","100%|██████████| 17/17 [00:03<00:00,  4.73it/s]\n","  0%|          | 0/65 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [359/1500] Training Loss: 0.0000172970 Valid Loss: 0.0005457980\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:51<00:00,  1.27it/s]\n","100%|██████████| 17/17 [00:03<00:00,  4.52it/s]\n","  0%|          | 0/65 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [360/1500] Training Loss: 0.0000210812 Valid Loss: 0.0005470608\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:50<00:00,  1.28it/s]\n","100%|██████████| 17/17 [00:03<00:00,  4.85it/s]\n","  0%|          | 0/65 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [361/1500] Training Loss: 0.0000170415 Valid Loss: 0.0005405662\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 65/65 [00:44<00:00,  1.46it/s]\n","100%|██████████| 17/17 [00:01<00:00, 10.25it/s]\n","  0%|          | 0/65 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [362/1500] Training Loss: 0.0000181677 Valid Loss: 0.0005243238\n"]},{"name":"stderr","output_type":"stream","text":[" 94%|█████████▍| 61/65 [00:40<00:03,  1.20it/s]"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     36\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 37\u001b[0m     loss_train_e \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m loss_train_e \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader_train)\n\u001b[1;32m     40\u001b[0m loss_train\u001b[38;5;241m.\u001b[39mappend(loss_train_e)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import torch.optim as optim\n","import pickle\n","\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.00001)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=len(dataloader_train)*10, gamma=0.9)        \n","\n","if fp16_training:\n","    print('Accelerate Prepare')\n","    \"\"\"\n","    model, optimizer, dataloader_train, dataloader_valid, scheduler = \\\n","        accelerator.prepare(model, optimizer, dataloader_train, dataloader_valid, scheduler)\"\"\"\n","    model, optimizer, dataloader_train, scheduler = accelerator.prepare(\n","            model, optimizer, dataloader_train, scheduler\n","        )\n","\n","num_epochs = 1500\n","for epoch in range(last_epoch, num_epochs):\n","    # Training phase\n","    model.train()\n","    loss_train_e = 0\n","    for batch_x, batch_y in tqdm(dataloader_train):\n","        if not fp16_training:\n","            batch_x = batch_x.to(device)\n","            batch_y = batch_y.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(batch_x)\n","\n","        # Loss\n","        loss = criterion(outputs, batch_y)\n","        if fp16_training:\n","            accelerator.backward(loss)\n","        else:\n","            loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        loss_train_e += loss.item()\n","        \n","    loss_train_e /= len(dataloader_train)\n","    loss_train.append(loss_train_e)\n","    \n","    loss_valid_e = 0\n","    with torch.no_grad():\n","        model.eval()\n","        for batch_x_val, batch_y_val in tqdm(dataloader_valid):\n","            if not fp16_training:\n","                batch_x_val = batch_x_val.to(device)\n","                batch_y_val = batch_y_val.to(device)\n","            outputs_val = model(batch_x_val)\n","            loss = criterion(outputs_val, batch_y_val)\n","            loss_valid_e += loss.item()\n","        loss_valid_e /= len(dataloader_valid)\n","        loss_valid.append(loss_valid_e)\n","            \n","        torch.save(model.state_dict(), f'Temp/Conformer_{stock_symbol}_checkpoint_LastTrainModel.pt')\n","        if loss_valid_e < min_val_loss:\n","            min_val_loss = loss_valid_e\n","            print(f'New best model found in epoch {epoch} with val loss: {min_val_loss}')\n","            torch.save(model.state_dict(), f'ConformerResult/Conformer_{stock_symbol}_best_model.pt')            \n","        if epoch % 50 == 0:\n","            pass\n","            # torch.save(model, f'ConformerResult/Conformerr_{stock_symbol}_checkpoint_{epoch}.pt')\n","            \n","    with open(f'Temp/Conformer_{stock_symbol}_TrainValHistLoss.pk', 'wb') as f:\n","        pickle.dump({'train': loss_train, 'valid': loss_valid}, f)\n","    with open(f'Temp/Conformer_{stock_symbol}_LastTrainInfo.pk', 'wb') as f:\n","        pickle.dump({'min val loss': min_val_loss, 'epoch': epoch, 'lr': optimizer.param_groups[0]['lr']}, f)\n","        \n","    # Print statistics\n","    print(f'Epoch [{epoch}/{num_epochs}]',\n","        f'Training Loss: {loss_train_e:.10f}',\n","        f'Valid Loss: {loss_valid_e:.10f}')"]},{"cell_type":"markdown","metadata":{"id":"gdsTCRhq_a_O"},"source":["# Validate Model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1708508308097,"user":{"displayName":"Kuo Jacob","userId":"03725230422177139348"},"user_tz":-480},"id":"Xr_xzxUygrCM"},"outputs":[],"source":["def load_model():\n","    import torch\n","    model = torch.load(f'ConformerResult/Conformer_{stock_symbol}_best_model.pt')\n","    return model\n","model = load_model()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":46476,"status":"ok","timestamp":1708508354571,"user":{"displayName":"Kuo Jacob","userId":"03725230422177139348"},"user_tz":-480},"id":"-Vxhjr2bfVrJ"},"outputs":[{"ename":"NameError","evalue":"name 'dataloader_test' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[18], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39msign(y_pred_tensor) \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39msign(y_test_tensor))\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(y_test_tensor)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y_pred_tensor, accuracy\n\u001b[0;32m---> 17\u001b[0m y_pred, acc \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(acc)\n","Cell \u001b[0;32mIn[18], line 3\u001b[0m, in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest\u001b[39m():\n\u001b[0;32m----> 3\u001b[0m     dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mdataloader_test\u001b[49m\n\u001b[1;32m      5\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      6\u001b[0m     s_pred \u001b[38;5;241m=\u001b[39m []\n","\u001b[0;31mNameError\u001b[0m: name 'dataloader_test' is not defined"]}],"source":["\n","import gc\n","def test():\n","    dataloader = dataloader_test\n","\n","    model.eval()\n","    s_pred = []\n","    s_true = []\n","    for x, y in tqdm(dataloader):\n","        y_pred = model(x)\n","        s_pred.append(y_pred.detach())\n","        s_true.append(y)\n","    y_pred_tensor = torch.concat(s_pred)\n","    y_test_tensor = torch.concat(s_true)\n","    accuracy = (torch.sign(y_pred_tensor) == torch.sign(y_test_tensor)).sum() / len(y_test_tensor)\n","    return y_pred_tensor, accuracy\n","\n","y_pred, acc = test()\n","print(acc)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18330,"status":"ok","timestamp":1708508372899,"user":{"displayName":"Kuo Jacob","userId":"03725230422177139348"},"user_tz":-480},"id":"wMKUVbcfj8zX"},"outputs":[],"source":["# Derive y_pred and y_train_pred of shape(N, 2) and numpy type\n","\n","y_pred_numpy = y_pred.cpu().numpy()\n","\n","# predict with train set\n","y_train_pred = model(torch.tensor(X[-100:], dtype = torch.float32))\n","y_train_numpy = y_train_pred.detach().cpu().numpy()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iKLtCWerEIac"},"outputs":[],"source":["import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","\n","# Scaling\n","prediction = pd.DataFrame(y_pred_numpy)\n","scaler = StandardScaler()\n","scaler.fit(y_train_numpy)\n","prediction = pd.DataFrame(scaler.transform(prediction))\n","\n","# Get the predicted price of O and C and Prediction merge with complete data\n","prediction.columns = ['pred_do_1', 'pred_dc_1']\n","prediction['Date'] = date\n","\n","true_and_pred = pd.merge(df.reset_index(), prediction, on = 'Date', how = 'left')\n","true_and_pred['pred_o'] = (true_and_pred['Open'] * (1 + true_and_pred['pred_do_1'])).shift(1)\n","true_and_pred['pred_c'] = (true_and_pred['Close'] * (1 + true_and_pred['pred_dc_1'])).shift(1)\n","true_and_pred['pred_oc'] = true_and_pred['pred_c'] - true_and_pred['pred_o']\n","true_and_pred['true_oc'] = true_and_pred['Close'] - true_and_pred['Open']\n","\n","# Backtest\n","asset_list = []\n","df_backtest = true_and_pred[['Open', 'Close', 'true_oc', 'pred_oc']].dropna()\n","asset = 1\n","for index, (o, c, true, pred) in df_backtest.iterrows():\n","    if pred > 0:\n","        returns = true/o\n","        asset *= (1 + returns)\n","    asset_list.append(asset)\n","\n","print(asset)\n","plt.plot(asset_list, label = 'resnet')\n","plt.plot(df_backtest.reset_index()['Close']/df_backtest['Close'].iloc[0], label = 'buy hold')\n","plt.legend()\n","plt.savefig('/ConformerResult/test_backtest.jpg')\n","# plt.show()"]}],"metadata":{"colab":{"collapsed_sections":["2dlPDr1feNdw","N2GtucuTfVrD","24AwH-nhes4f"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
