{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# Define the basic block with skip connection\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != self.expansion * out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += self.shortcut(residual)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# Define the ResNet model\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=1):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(5, 64, kernel_size=3, stride=1, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return torch.tanh(x)\n",
    "\n",
    "# Create the ResNet-50 model\n",
    "def resnet50(num_classes):\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import copy\n",
    "\n",
    "def train(dataloader_train, dataloader_valid, transform = ''):\n",
    "    num_class = y_train.shape[1]\n",
    "    # Instantiate the model\n",
    "    model = resnet50(num_class).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.0001, weight_decay=0.01)\n",
    "\n",
    "    num_epochs = 100\n",
    "    min_val_loss = 1000\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        for batch_x, batch_y in dataloader_train:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        model.eval()\n",
    "        val_loss = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_x_val, batch_y_val in dataloader_valid:\n",
    "                outputs_val = model(batch_x_val)\n",
    "                loss_val = criterion(outputs_val, batch_y_val)\n",
    "                val_loss.append(loss_val.item())\n",
    "            if sum(val_loss) < min_val_loss:\n",
    "                min_val_loss = sum(val_loss)\n",
    "                best_model = model\n",
    "                torch.save(model, f'resnet/best_model.pt')\n",
    "\n",
    "            if epoch % 50 == 0:\n",
    "                torch.save(model, f'resnet/checkpoint_{epoch}.pt')\n",
    "\n",
    "            # Print statistics\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}]',\n",
    "                f'Training Loss: {loss.item():.10f}',\n",
    "                f'Valid Loss: {sum(val_loss)/64:.10f}')\n",
    "\n",
    "train(dataloader_train, dataloader_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(mode, device = 'cpu'):\n",
    "    import torch\n",
    "    model = torch.load(f'/content/drive/MyDrive/chen_resnet/result/{device}/{mode}_best_model.pt')\n",
    "    return model\n",
    "if y_mode == 'dodc':\n",
    "    dodc_model = load_model('dodc')\n",
    "elif y_mode == 'do':\n",
    "    do_model = load_model('do')\n",
    "    dc_model = load_model('dc')\n",
    "elif y_mode == '(o-c)':\n",
    "    dc_model = load_model('dc')\n",
    "    oc_model = load_model('(o-c)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def test(mode, device = 'cpu'):\n",
    "    gc.collect()\n",
    "    if mode == 'do':\n",
    "        model = do_model\n",
    "        dataloader = dataloader_test_do\n",
    "    elif mode == 'dc':\n",
    "        model = dc_model\n",
    "        dataloader = dataloader_test_dc\n",
    "    elif mode == '(o-c)':\n",
    "        model = oc_model\n",
    "        dataloader = dataloader_test_oc\n",
    "    elif mode == 'dodc':\n",
    "        model = dodc_model\n",
    "        dataloader = dataloader_test\n",
    "\n",
    "    model.eval()\n",
    "    s_pred = []\n",
    "    s_true = []\n",
    "    for x, y in dataloader:\n",
    "        y_pred = model(x)\n",
    "        s_pred.append(y_pred.detach())\n",
    "        s_true.append(y)\n",
    "    y_pred_tensor = torch.concat(s_pred)\n",
    "    y_test_tensor = torch.concat(s_true)\n",
    "    accuracy = (torch.sign(y_pred_tensor) == torch.sign(y_test_tensor)).sum() / len(y_test_tensor)\n",
    "    return y_pred_tensor, accuracy\n",
    "\n",
    "if y_mode == 'dodc':\n",
    "    y_pred, acc = test(y_mode, device)\n",
    "elif y_mode == 'do':\n",
    "    y_pred_do, acc_do = test('do', device)\n",
    "    y_pred_dc, acc_dc = test('dc', device)\n",
    "elif y_mode == '(o-c)':\n",
    "    y_pred_dc, acc_dc = test('dc', device)\n",
    "    y_pred_oc, acc_oc = test('(o-c)', device)\n",
    "    print(acc_oc, acc_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive y_pred and y_train_pred of shape(N, 2) and numpy type\n",
    "\n",
    "if y_mode == 'dodc':\n",
    "    y_pred_numpy = y_pred.cpu().numpy()\n",
    "\n",
    "    # predict with train set\n",
    "    y_train_pred = dodc_model(torch.tensor(X[-100:], dtype = torch.float32))\n",
    "    y_train_numpy = y_train_pred.detach().cpu().numpy()\n",
    "\n",
    "elif y_mode == 'dc':\n",
    "    y_pred_tensor = torch.cat((y_pred_do, y_pred_dc), dim = 1)\n",
    "    y_pred_numpy = y_pred_tensor.cpu().numpy()\n",
    "\n",
    "    # predict with train set\n",
    "    y_trainpred_do = do_model(torch.tensor(X_do[-100:], dtype = torch.float32))\n",
    "    y_trainpred_dc = dc_model(torch.tensor(X_dc[-100:], dtype = torch.float32))\n",
    "    y_train_pred = torch.cat((y_trainpred_do, y_trainpred_dc), dim = 1)\n",
    "    y_train_numpy = y_train_pred.detach().cpu().numpy()\n",
    "\n",
    "elif y_mode == '(o-c)':\n",
    "    y_pred_tensor = torch.cat((y_pred_oc, y_pred_dc), dim = 1)\n",
    "    y_pred_numpy = y_pred_tensor.cpu().numpy()\n",
    "\n",
    "    # predict with train set\n",
    "    y_trainpred_oc = oc_model(torch.tensor(X_oc[-100:], dtype = torch.float32))\n",
    "    y_trainpred_dc = dc_model(torch.tensor(X_dc[-100:], dtype = torch.float32))\n",
    "    y_train_pred = torch.cat((y_trainpred_oc, y_trainpred_dc), dim = 1)\n",
    "    y_train_numpy = y_train_pred.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scaling\n",
    "prediction = pd.DataFrame(y_pred_numpy)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(y_train_numpy)\n",
    "prediction = pd.DataFrame(scaler.transform(prediction))\n",
    "\n",
    "# Get the predicted price of O and C and Prediction merge with complete data\n",
    "if y_mode == 'do' or y_mode == 'dodc':\n",
    "    prediction.columns = ['pred_do_1', 'pred_dc_1']\n",
    "    prediction['Date'] = date\n",
    "\n",
    "    true_and_pred = pd.merge(df.reset_index(), prediction, on = 'Date', how = 'left')\n",
    "    true_and_pred['pred_o'] = (true_and_pred['Open'] * (1 + true_and_pred['pred_do_1'])).shift(1)\n",
    "    true_and_pred['pred_c'] = (true_and_pred['Close'] * (1 + true_and_pred['pred_dc_1'])).shift(1)\n",
    "    true_and_pred['pred_oc'] = true_and_pred['pred_c'] - true_and_pred['pred_o']\n",
    "    true_and_pred['true_oc'] = true_and_pred['Close'] - true_and_pred['Open']\n",
    "\n",
    "if y_mode == '(o-c)':\n",
    "    prediction.columns = ['pred_oc_1', 'pred_dc_1']\n",
    "    prediction['Date'] = date\n",
    "\n",
    "    true_and_pred = pd.merge(df.reset_index(), prediction, on = 'Date', how = 'left')\n",
    "    true_and_pred['pred_o'] = (true_and_pred['Close'] * (1 + true_and_pred['pred_oc_1'])).shift(1)\n",
    "    true_and_pred['pred_c'] = (true_and_pred['Close'] * (1 + true_and_pred['pred_dc_1'])).shift(1)\n",
    "    true_and_pred['pred_oc'] = true_and_pred['pred_c'] - true_and_pred['pred_o']\n",
    "    true_and_pred['true_oc'] = true_and_pred['Close'] - true_and_pred['Open']\n",
    "\n",
    "\n",
    "# Backtest\n",
    "asset_list = []\n",
    "df_backtest = true_and_pred[['Open', 'Close', 'true_oc', 'pred_oc']].dropna()\n",
    "asset = 1\n",
    "for index, (o, c, true, pred) in df_backtest.iterrows():\n",
    "    if pred > 0:\n",
    "        returns = true/o\n",
    "        asset *= (1 + returns)\n",
    "    asset_list.append(asset)\n",
    "\n",
    "print(asset)\n",
    "plt.plot(asset_list, label = 'resnet')\n",
    "plt.plot(df_backtest.reset_index()['Close']/df_backtest['Close'].iloc[0], label = 'buy hold')\n",
    "plt.legend()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
